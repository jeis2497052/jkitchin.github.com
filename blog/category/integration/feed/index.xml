<?xml version="1.0" encoding="UTF-8"?>

<rss version="2.0"
     xmlns:content="http://purl.org/rss/1.0/modules/content/"
     xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
     xmlns:atom="http://www.w3.org/2005/Atom"
     xmlns:dc="http://purl.org/dc/elements/1.1/"
     xmlns:wfw="http://wellformedweb.org/CommentAPI/"
     >
  <channel>
    <atom:link href="http://kitchingroup.cheme.cmu.edu/blog/feed/index.xml" rel="self" type="application/rss+xml" />
    <title>The Kitchin Research Group</title>
    <link>http://jkitchin.github.io/blog</link>
    <description>Chemical Engineering at Carnegie Mellon University</description>
    <pubDate>Wed, 12 Apr 2017 11:55:46 GMT</pubDate>
    <generator>Blogofile</generator>
    <sy:updatePeriod>hourly</sy:updatePeriod>
    <sy:updateFrequency>1</sy:updateFrequency>
    
    <item>
      <title>Numerical Simpsons rule</title>
      <link>http://jkitchin.github.io/blog/2013/03/08/Numerical-Simpsons-rule</link>
      <pubDate>Fri, 08 Mar 2013 18:18:55 EST</pubDate>
      <category><![CDATA[integration]]></category>
      <category><![CDATA[math]]></category>
      <guid isPermaLink="false">vmtnHrNkUcTa2PmQCOP7XnVGrO0=</guid>
      <description>Numerical Simpsons rule</description>
      <content:encoded><![CDATA[


&lt;p&gt;

A more accurate numerical integration than the trapezoid method is &lt;a href="http://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.simps.html" &gt;Simpson's rule&lt;/a&gt;. The syntax is similar to trapz, but the method is in scipy.integrate.
&lt;/p&gt;

&lt;div class="org-src-container"&gt;

&lt;pre class="src src-python"&gt;&lt;span style="color: #8b0000;"&gt;import&lt;/span&gt; numpy &lt;span style="color: #8b0000;"&gt;as&lt;/span&gt; np
&lt;span style="color: #8b0000;"&gt;from&lt;/span&gt; scipy.integrate &lt;span style="color: #8b0000;"&gt;import&lt;/span&gt; simps, romb

a = 0.0; b = np.pi / 4.0;
N = 10  &lt;span style="color: #ff0000; font-weight: bold;"&gt;# this is the number of intervals&lt;/span&gt;

x = np.linspace(a, b, N)
y = np.cos(x)

t = np.trapz(y, x)
s = simps(y, x)
a = np.sin(b) - np.sin(a)

&lt;span style="color: #8b0000;"&gt;print&lt;/span&gt;
&lt;span style="color: #8b0000;"&gt;print&lt;/span&gt; &lt;span style="color: #228b22;"&gt;'trapz = {0} ({1:%} error)'&lt;/span&gt;.format(t, (t - a)/a)
&lt;span style="color: #8b0000;"&gt;print&lt;/span&gt; &lt;span style="color: #228b22;"&gt;'simps = {0} ({1:%} error)'&lt;/span&gt;.format(s, (s - a)/a)
&lt;span style="color: #8b0000;"&gt;print&lt;/span&gt; &lt;span style="color: #228b22;"&gt;'analy = {0}'&lt;/span&gt;.format(a)
&lt;/pre&gt;
&lt;/div&gt;

&lt;pre class="example"&gt;
&amp;gt;&amp;gt;&amp;gt; &amp;gt;&amp;gt;&amp;gt; &amp;gt;&amp;gt;&amp;gt; &amp;gt;&amp;gt;&amp;gt; &amp;gt;&amp;gt;&amp;gt; &amp;gt;&amp;gt;&amp;gt; &amp;gt;&amp;gt;&amp;gt; &amp;gt;&amp;gt;&amp;gt; &amp;gt;&amp;gt;&amp;gt; &amp;gt;&amp;gt;&amp;gt; &amp;gt;&amp;gt;&amp;gt; &amp;gt;&amp;gt;&amp;gt;
trapz = 0.70665798038 (-0.063470% error)
simps = 0.707058914216 (-0.006769% error)
analy = 0.707106781187
&lt;/pre&gt;

&lt;p&gt;
You can see the Simpson's method is more accurate than the trapezoid method.
&lt;/p&gt;
&lt;p&gt;Copyright (C) 2013 by John Kitchin. See the &lt;a href="/copying.html"&gt;License&lt;/a&gt; for information about copying.&lt;p&gt;&lt;p&gt;&lt;a href="/org/2013/03/08/Numerical-Simpsons-rule.org"&gt;org-mode source&lt;/a&gt;&lt;p&gt;]]></content:encoded>
    </item>
    <item>
      <title>Integrating the Fermi distribution to compute entropy</title>
      <link>http://jkitchin.github.io/blog/2013/03/06/Integrating-the-Fermi-distribution-to-compute-entropy</link>
      <pubDate>Wed, 06 Mar 2013 09:39:42 EST</pubDate>
      <category><![CDATA[integration]]></category>
      <category><![CDATA[gotcha]]></category>
      <category><![CDATA[dft]]></category>
      <guid isPermaLink="false">8aXB-dJ08KwHSy4vBZ0lsSIkMoU=</guid>
      <description>Integrating the Fermi distribution to compute entropy</description>
      <content:encoded><![CDATA[



&lt;p&gt;
The Fermi distribution is defined by \(f(\epsilon) = \frac{1}{e^{(\epsilon - \mu)/(k T)} + 1}\). This function describes the occupation of energy levels at temperatures above absolute zero. We use this function to compute electronic entropy in a metal, which contains an integral of \(\int n(\epsilon) (f \ln f + (1 - f) \ln (1-f)) d\epsilon\), where \(n(\epsilon)\) is the electronic density of states. Here we plot the Fermi distribution function. It shows that well below the Fermi level the states are fully occupied, and well above the Fermi level, they are unoccupied. Near the Fermi level, the states go from occupied to unoccupied smoothly.
&lt;/p&gt;

&lt;div class="org-src-container"&gt;

&lt;pre class="src src-python"&gt;&lt;span style="color: #8b0000;"&gt;import&lt;/span&gt; numpy &lt;span style="color: #8b0000;"&gt;as&lt;/span&gt; np
&lt;span style="color: #8b0000;"&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style="color: #8b0000;"&gt;as&lt;/span&gt; plt

mu = 0
k = 8.6e-5
T = 1000

&lt;span style="color: #8b0000;"&gt;def&lt;/span&gt; &lt;span style="color: #8b2323;"&gt;f&lt;/span&gt;(e):
    &lt;span style="color: #8b0000;"&gt;return&lt;/span&gt; 1.0 / (np.exp((e - mu)/(k*T)) + 1)

espan = np.linspace(-10, 10, 200)
plt.plot(espan, f(espan))
plt.ylim([-0.1, 1.1])
plt.savefig(&lt;span style="color: #228b22;"&gt;'images/fermi-entropy-integrand-1.png'&lt;/span&gt;)
&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;img src="/img/./images/fermi-entropy-integrand-1.png"&gt;&lt;p&gt;

&lt;p&gt;
Let us consider a simple density of states function, just a parabola. This could represent a s-band for example. We will use this function to explore the integral.
&lt;/p&gt;

&lt;div class="org-src-container"&gt;

&lt;pre class="src src-python"&gt;&lt;span style="color: #8b0000;"&gt;import&lt;/span&gt; numpy &lt;span style="color: #8b0000;"&gt;as&lt;/span&gt; np
&lt;span style="color: #8b0000;"&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style="color: #8b0000;"&gt;as&lt;/span&gt; plt

mu = 0
k = 8.6e-5
T = 1000

&lt;span style="color: #8b0000;"&gt;def&lt;/span&gt; &lt;span style="color: #8b2323;"&gt;f&lt;/span&gt;(e):
    &lt;span style="color: #8b0000;"&gt;return&lt;/span&gt; 1.0 / (np.exp((e - mu)/(k*T)) + 1)

&lt;span style="color: #8b0000;"&gt;def&lt;/span&gt; &lt;span style="color: #8b2323;"&gt;dos&lt;/span&gt;(e):
    d = (np.ones(e.shape) - 0.03 * e**2) 
    &lt;span style="color: #8b0000;"&gt;return&lt;/span&gt; d * (d &amp;gt; 0)
espan = np.linspace(-10, 10)

plt.plot(espan, dos(espan), label=&lt;span style="color: #228b22;"&gt;'Total dos'&lt;/span&gt;)
plt.plot(espan, f(espan) * dos(espan), label=&lt;span style="color: #228b22;"&gt;'Occupied states'&lt;/span&gt;)
plt.legend(loc=&lt;span style="color: #228b22;"&gt;'best'&lt;/span&gt;)
plt.savefig(&lt;span style="color: #228b22;"&gt;'images/fermi-entropy-integrand-2.png'&lt;/span&gt;)
&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;
&lt;p&gt;&lt;img src="/img/./images/fermi-entropy-integrand-2.png"&gt;&lt;p&gt;
Now, we consider the integral to compute the electronic entropy. The entropy is proportional to this integral.
&lt;/p&gt;

&lt;p&gt;
\( \int n(\epsilon) (f \ln f + (1 - f) \ln (1-f)) d\epsilon \)
&lt;/p&gt;

&lt;p&gt;
It looks straightforward to compute, but it turns out there is a wrinkle. Evaluating the integrand leads to &lt;code&gt;nan&lt;/code&gt; elements because the ln(0) is -&amp;infin;. 
&lt;/p&gt;

&lt;div class="org-src-container"&gt;

&lt;pre class="src src-python"&gt;&lt;span style="color: #8b0000;"&gt;import&lt;/span&gt; numpy &lt;span style="color: #8b0000;"&gt;as&lt;/span&gt; np
mu = 0
k = 8.6e-5
T = 100

&lt;span style="color: #8b0000;"&gt;def&lt;/span&gt; &lt;span style="color: #8b2323;"&gt;fermi&lt;/span&gt;(e):
    &lt;span style="color: #8b0000;"&gt;return&lt;/span&gt; 1.0 / (np.exp((e - mu)/(k*T)) + 1)

espan = np.array([-20, -10, -5, 0.0, 5, 10])
f = fermi(espan)

&lt;span style="color: #8b0000;"&gt;print&lt;/span&gt; f * np.log(f)
&lt;span style="color: #8b0000;"&gt;print&lt;/span&gt; (1 - f) * np.log(1 - f)
&lt;/pre&gt;
&lt;/div&gt;

&lt;pre class="example"&gt;
[  0.00000000e+000   0.00000000e+000   0.00000000e+000  -3.46573590e-001
  -1.85216532e-250               nan]
[        nan         nan         nan -0.34657359  0.          0.        ]
&lt;/pre&gt;

&lt;p&gt;
In this case, these &lt;code&gt;nan&lt;/code&gt; elements should be equal to zero (x ln(x) goes to zero as x goes to zero). So, we can just ignore those elements in the integral. Here is how to do that.
&lt;/p&gt;

&lt;div class="org-src-container"&gt;

&lt;pre class="src src-python"&gt;&lt;span style="color: #8b0000;"&gt;import&lt;/span&gt; numpy &lt;span style="color: #8b0000;"&gt;as&lt;/span&gt; np
&lt;span style="color: #8b0000;"&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style="color: #8b0000;"&gt;as&lt;/span&gt; plt

mu = 0
k = 8.6e-5
T = 1000

&lt;span style="color: #8b0000;"&gt;def&lt;/span&gt; &lt;span style="color: #8b2323;"&gt;fermi&lt;/span&gt;(e):
    &lt;span style="color: #8b0000;"&gt;return&lt;/span&gt; 1.0 / (np.exp((e - mu)/(k*T)) + 1)

&lt;span style="color: #8b0000;"&gt;def&lt;/span&gt; &lt;span style="color: #8b2323;"&gt;dos&lt;/span&gt;(e):
    d = (np.ones(e.shape) - 0.03 * e**2) 
    &lt;span style="color: #8b0000;"&gt;return&lt;/span&gt; d * (d &amp;gt; 0)

espan = np.linspace(-20, 10)
f = fermi(espan)
n = dos(espan)

g = n * (f * np.log(f) + (1 - f) * np.log(1 - f))

&lt;span style="color: #8b0000;"&gt;print&lt;/span&gt; np.trapz(espan, g) &lt;span style="color: #ff0000; font-weight: bold;"&gt;# &lt;/span&gt;&lt;span style="color: #ff0000; font-weight: bold;"&gt;nan because of the nan in the g vector&lt;/span&gt;
&lt;span style="color: #8b0000;"&gt;print&lt;/span&gt; g

plt.plot(espan, g)
plt.savefig(&lt;span style="color: #228b22;"&gt;'images/fermi-entropy-integrand-3.png'&lt;/span&gt;)

&lt;span style="color: #ff0000; font-weight: bold;"&gt;# &lt;/span&gt;&lt;span style="color: #ff0000; font-weight: bold;"&gt;find the elements that are not nan&lt;/span&gt;
ind = np.logical_not(np.isnan(g))

&lt;span style="color: #ff0000; font-weight: bold;"&gt;# &lt;/span&gt;&lt;span style="color: #ff0000; font-weight: bold;"&gt;evaluate the integrand for only those points&lt;/span&gt;
&lt;span style="color: #8b0000;"&gt;print&lt;/span&gt; np.trapz(espan[ind], g[ind])
&lt;/pre&gt;
&lt;/div&gt;

&lt;pre class="example"&gt;
nan
[             nan              nan              nan              nan
              nan              nan              nan              nan
              nan              nan              nan              nan
              nan              nan              nan              nan
              nan              nan              nan              nan
              nan              nan              nan              nan
              nan              nan              nan              nan
  -9.75109643e-14  -1.05987106e-10  -1.04640574e-07  -8.76265644e-05
  -4.92684641e-02  -2.91047740e-01  -7.75652579e-04  -1.00962241e-06
  -1.06972936e-09  -1.00527877e-12  -8.36436686e-16  -6.48930917e-19
  -4.37946336e-22  -2.23285389e-25  -1.88578082e-29   0.00000000e+00
   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   0.00000000e+00]
0.208886080897
&lt;/pre&gt;

&lt;p&gt;&lt;img src="/img/./images/fermi-entropy-integrand-3.png"&gt;&lt;p&gt;

&lt;p&gt;
The integrand is pretty well behaved in the figure above. You do not see the full range of the x-axis, because the integrand evaluates to &lt;code&gt;nan&lt;/code&gt; for very negative numbers. This causes the &lt;code&gt;trapz&lt;/code&gt; function to return &lt;code&gt;nan&lt;/code&gt; also. We can solve the problem by only integrating the parts that are not &lt;code&gt;nan&lt;/code&gt;. We have to use numpy.logical&lt;sub&gt;not&lt;/sub&gt; to get an element-wise array of which elements are not &lt;code&gt;nan&lt;/code&gt;. In this example, the integrand is not well sampled, so the area under that curve may not be very accurate. 
&lt;/p&gt;
&lt;p&gt;Copyright (C) 2013 by John Kitchin. See the &lt;a href="/copying.html"&gt;License&lt;/a&gt; for information about copying.&lt;p&gt;&lt;p&gt;&lt;a href="/org/2013/03/06/Integrating-the-Fermi-distribution-to-compute-entropy.org"&gt;org-mode source&lt;/a&gt;&lt;p&gt;]]></content:encoded>
    </item>
    <item>
      <title>The trapezoidal method of integration</title>
      <link>http://jkitchin.github.io/blog/2013/02/23/The-trapezoidal-method-of-integration</link>
      <pubDate>Sat, 23 Feb 2013 09:00:00 EST</pubDate>
      <category><![CDATA[integration]]></category>
      <category><![CDATA[math]]></category>
      <guid isPermaLink="false">OoBUv1RqAYMTrxhLlW5Lh-Ll43I=</guid>
      <description>The trapezoidal method of integration</description>
      <content:encoded><![CDATA[


&lt;p&gt;
&lt;a href="http://matlab.cheme.cmu.edu/2011/10/14/the-trapezoidal-method-of-integration/" &gt;Matlab post&lt;/a&gt;

See &lt;a href="http://en.wikipedia.org/wiki/Trapezoidal_rule" &gt;http://en.wikipedia.org/wiki/Trapezoidal_rule&lt;/a&gt;
&lt;/p&gt;

&lt;p&gt;
$$\int_a^b f(x) dx \approx \frac{1}{2}\displaystyle\sum\limits_{k=1}^N(x_{k+1}-x_k)(f(x_{k+1}) + f(x_k))$$
&lt;/p&gt;

&lt;p&gt;
Let us compute the integral of sin(x) from x=0 to \(\pi\). To approximate the integral, we need to divide the interval from \(a\) to \(b\) into \(N\) intervals. The analytical answer is 2.0.
&lt;/p&gt;

&lt;p&gt;
We will use this example to illustrate the difference in performance between loops and vectorized operations in python.
&lt;/p&gt;

&lt;div class="org-src-container"&gt;

&lt;pre class="src src-python"&gt;&lt;span style="color: #8b0000;"&gt;import&lt;/span&gt; numpy &lt;span style="color: #8b0000;"&gt;as&lt;/span&gt; np
&lt;span style="color: #8b0000;"&gt;import&lt;/span&gt; time

a = 0.0; b = np.pi;
N = 1000; &lt;span style="color: #ff0000; font-weight: bold;"&gt;# this is the number of intervals&lt;/span&gt;

h = (b - a)/N; &lt;span style="color: #ff0000; font-weight: bold;"&gt;# this is the width of each interval&lt;/span&gt;
x = np.linspace(a, b, N) 
y = np.sin(x); &lt;span style="color: #ff0000; font-weight: bold;"&gt;# the sin function is already vectorized&lt;/span&gt;

t0 = time.time()
f = 0.0
&lt;span style="color: #8b0000;"&gt;for&lt;/span&gt; k &lt;span style="color: #8b0000;"&gt;in&lt;/span&gt; &lt;span style="color: #8b0000;"&gt;range&lt;/span&gt;(len(x) - 1):
    f += 0.5 * ((x[k+1] - x[k]) * (y[k+1] + y[k]))

tf = time.time() - t0
&lt;span style="color: #8b0000;"&gt;print&lt;/span&gt; &lt;span style="color: #228b22;"&gt;'time elapsed = {0} sec'&lt;/span&gt;.format(tf)

&lt;span style="color: #8b0000;"&gt;print&lt;/span&gt; f
&lt;/pre&gt;
&lt;/div&gt;

&lt;pre class="example"&gt;
&amp;gt;&amp;gt;&amp;gt; &amp;gt;&amp;gt;&amp;gt; &amp;gt;&amp;gt;&amp;gt; &amp;gt;&amp;gt;&amp;gt; &amp;gt;&amp;gt;&amp;gt; &amp;gt;&amp;gt;&amp;gt; &amp;gt;&amp;gt;&amp;gt; &amp;gt;&amp;gt;&amp;gt; &amp;gt;&amp;gt;&amp;gt; &amp;gt;&amp;gt;&amp;gt; &amp;gt;&amp;gt;&amp;gt; ... ... &amp;gt;&amp;gt;&amp;gt; &amp;gt;&amp;gt;&amp;gt; time elapsed = 0.0780000686646 sec
&amp;gt;&amp;gt;&amp;gt; 1.99999835177
&lt;/pre&gt;

&lt;div class="org-src-container"&gt;

&lt;pre class="src src-python"&gt;t0 = time.time()
Xk = x[1:-1] - x[0:-2] &lt;span style="color: #ff0000; font-weight: bold;"&gt;# vectorized version of (x[k+1] - x[k])&lt;/span&gt;
Yk = y[1:-1] + y[0:-2] &lt;span style="color: #ff0000; font-weight: bold;"&gt;# vectorized version of (y[k+1] + y[k])&lt;/span&gt;

f = 0.5 * np.sum(Xk * Yk) &lt;span style="color: #ff0000; font-weight: bold;"&gt;# vectorized version of the loop above&lt;/span&gt;
tf = time.time() - t0
&lt;span style="color: #8b0000;"&gt;print&lt;/span&gt; &lt;span style="color: #228b22;"&gt;'time elapsed = {0} sec'&lt;/span&gt;.format(tf)

&lt;span style="color: #8b0000;"&gt;print&lt;/span&gt; f
&lt;/pre&gt;
&lt;/div&gt;

&lt;pre class="example"&gt;
&amp;gt;&amp;gt;&amp;gt; &amp;gt;&amp;gt;&amp;gt; &amp;gt;&amp;gt;&amp;gt; &amp;gt;&amp;gt;&amp;gt; &amp;gt;&amp;gt;&amp;gt; time elapsed = 0.077999830246 sec
&amp;gt;&amp;gt;&amp;gt; 1.99999340709
&lt;/pre&gt;

&lt;p&gt;
In the last example, there may be loop buried in the sum command. Let us do one final method, using linear algebra, in a single line. The key to understanding this is to recognize the sum is just the result of a dot product of the x differences and y sums. 
&lt;/p&gt;

&lt;div class="org-src-container"&gt;

&lt;pre class="src src-python"&gt;t0 = time.time()
f = 0.5 * np.dot(Xk, Yk)
tf = time.time() - t0
&lt;span style="color: #8b0000;"&gt;print&lt;/span&gt; &lt;span style="color: #228b22;"&gt;'time elapsed = {0} sec'&lt;/span&gt;.format(tf)

&lt;span style="color: #8b0000;"&gt;print&lt;/span&gt; f
&lt;/pre&gt;
&lt;/div&gt;

&lt;pre class="example"&gt;
&amp;gt;&amp;gt;&amp;gt; &amp;gt;&amp;gt;&amp;gt; time elapsed = 0.0310001373291 sec
&amp;gt;&amp;gt;&amp;gt; 1.99999340709
&lt;/pre&gt;

&lt;p&gt;
The loop method is straightforward to code, and looks alot like the formula that defines the trapezoid method. the vectorized methods are not as easy to read, and take fewer lines of code to write. However, the vectorized methods are much faster than the loop, so the loss of readability could be worth it for very large problems.
&lt;/p&gt;

&lt;p&gt;
The times here are considerably slower than in Matlab. I am not sure if that is a totally fair comparison. Here I am running python through emacs, which may result in slower performance. I also used a very crude way of timing the performance which lumps some system performance in too.
&lt;/p&gt;
&lt;p&gt;Copyright (C) 2013 by John Kitchin. See the &lt;a href="/copying.html"&gt;License&lt;/a&gt; for information about copying.&lt;p&gt;&lt;p&gt;&lt;a href="/org/2013/02/23/The-trapezoidal-method-of-integration.org"&gt;org-mode source&lt;/a&gt;&lt;p&gt;]]></content:encoded>
    </item>
    <item>
      <title>On the quad or trapz'd in ChemE heaven</title>
      <link>http://jkitchin.github.io/blog/2013/02/02/On-the-quad-or-trapz-d-in-ChemE-heaven</link>
      <pubDate>Sat, 02 Feb 2013 09:00:00 EST</pubDate>
      <category><![CDATA[integration]]></category>
      <category><![CDATA[python]]></category>
      <guid isPermaLink="false">EqaOpRz5kzU1FTJtv24K73sy730=</guid>
      <description>On the quad or trapz'd in ChemE heaven</description>
      <content:encoded><![CDATA[


&lt;p&gt;


&lt;a href="http://matlab.cheme.cmu.edu/2011/09/12/on-the-quad-or-trapzd-in-cheme-heaven/" &gt;Matlab post&lt;/a&gt;
&lt;/p&gt;

&lt;p&gt;
What is the difference between quad and trapz? The short answer is that quad integrates functions (via a function handle) using numerical quadrature, and trapz performs integration of arrays of data using the trapezoid method.
&lt;/p&gt;

&lt;p&gt;
Let us look at some examples. We consider the example of computing \(\int_0^2 x^3 dx\). the analytical integral is \(1/4 x^4\), so we know the integral evaluates to 16/4 = 4. This will be our benchmark for comparison to the numerical methods.
&lt;/p&gt;

&lt;p&gt;
We use the scipy.integrate.quad command  to evaluate this \(\int_0^2 x^3 dx\).
&lt;/p&gt;

&lt;div class="org-src-container"&gt;

&lt;pre class="src src-python"&gt;&lt;span style="color: #8b0000;"&gt;from&lt;/span&gt; scipy.integrate &lt;span style="color: #8b0000;"&gt;import&lt;/span&gt; quad

ans, err = quad(&lt;span style="color: #8b0000;"&gt;lambda&lt;/span&gt; x: x**3, 0, 2)
&lt;span style="color: #8b0000;"&gt;print&lt;/span&gt; ans
&lt;/pre&gt;
&lt;/div&gt;

&lt;pre class="example"&gt;
4.0
&lt;/pre&gt;

&lt;p&gt;
you can also define a function for the integrand.
&lt;/p&gt;

&lt;div class="org-src-container"&gt;

&lt;pre class="src src-python"&gt;&lt;span style="color: #8b0000;"&gt;from&lt;/span&gt; scipy.integrate &lt;span style="color: #8b0000;"&gt;import&lt;/span&gt; quad

&lt;span style="color: #8b0000;"&gt;def&lt;/span&gt; &lt;span style="color: #8b2323;"&gt;integrand&lt;/span&gt;(x):
    &lt;span style="color: #8b0000;"&gt;return&lt;/span&gt; x**3

ans, err = quad(integrand, 0, 2)
&lt;span style="color: #8b0000;"&gt;print&lt;/span&gt; ans
&lt;/pre&gt;
&lt;/div&gt;

&lt;pre class="example"&gt;
4.0
&lt;/pre&gt;

&lt;div id="outline-container-1" class="outline-2"&gt;
&lt;h2 id="sec-1"&gt;&lt;span class="section-number-2"&gt;1&lt;/span&gt; Numerical data integration&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-1"&gt;
&lt;p&gt;
if we had numerical data like this, we use trapz to integrate it
&lt;/p&gt;

&lt;div class="org-src-container"&gt;

&lt;pre class="src src-python"&gt;&lt;span style="color: #8b0000;"&gt;import&lt;/span&gt; numpy &lt;span style="color: #8b0000;"&gt;as&lt;/span&gt; np

x = np.array([0, 0.5, 1, 1.5, 2])
y = x**3

i2 = np.trapz(y, x)

error = (i2 - 4)/4

&lt;span style="color: #8b0000;"&gt;print&lt;/span&gt; i2, error
&lt;/pre&gt;
&lt;/div&gt;

&lt;pre class="example"&gt;
4.25 0.0625
&lt;/pre&gt;

&lt;p&gt;
Note the integral of these vectors is greater than 4! You can see why here.
&lt;/p&gt;

&lt;div class="org-src-container"&gt;

&lt;pre class="src src-python"&gt;&lt;span style="color: #8b0000;"&gt;import&lt;/span&gt; numpy &lt;span style="color: #8b0000;"&gt;as&lt;/span&gt; np
&lt;span style="color: #8b0000;"&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style="color: #8b0000;"&gt;as&lt;/span&gt; plt
x = np.array([0, 0.5, 1, 1.5, 2])
y = x**3

x2 = np.linspace(0, 2)
y2 = x2**3

plt.plot(x, y, label=&lt;span style="color: #228b22;"&gt;'5 points'&lt;/span&gt;)
plt.plot(x2, y2, label=&lt;span style="color: #228b22;"&gt;'50 points'&lt;/span&gt;)
plt.legend()
plt.savefig(&lt;span style="color: #228b22;"&gt;'images/quad-1.png'&lt;/span&gt;)
&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;img src="/img/./images/quad-1.png"&gt;&lt;p&gt;

&lt;p&gt;
The trapezoid method is overestimating the area significantly. With more points, we get much closer to the analytical value.
&lt;/p&gt;

&lt;div class="org-src-container"&gt;

&lt;pre class="src src-python"&gt;&lt;span style="color: #8b0000;"&gt;import&lt;/span&gt; numpy &lt;span style="color: #8b0000;"&gt;as&lt;/span&gt; np

x2 = np.linspace(0, 2, 100)
y2 = x2**3

&lt;span style="color: #8b0000;"&gt;print&lt;/span&gt; np.trapz(y2, x2)
&lt;/pre&gt;
&lt;/div&gt;

&lt;pre class="example"&gt;
4.00040812162
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-2" class="outline-2"&gt;
&lt;h2 id="sec-2"&gt;&lt;span class="section-number-2"&gt;2&lt;/span&gt; Combining numerical data with quad&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-2"&gt;
&lt;p&gt;
You might want to combine numerical data with the quad function if you want to perform integrals easily. Let us say you are given this data:
&lt;/p&gt;

&lt;p&gt;
x = [0 0.5 1 1.5 2];
y = [0    0.1250    1.0000    3.3750    8.0000];
&lt;/p&gt;

&lt;p&gt;
and you want to integrate this from x = 0.25 to 1.75. We do not have data in those regions, so some interpolation is going to be needed. Here is one approach.
&lt;/p&gt;

&lt;div class="org-src-container"&gt;

&lt;pre class="src src-python"&gt;&lt;span style="color: #8b0000;"&gt;from&lt;/span&gt; scipy.interpolate &lt;span style="color: #8b0000;"&gt;import&lt;/span&gt; interp1d
&lt;span style="color: #8b0000;"&gt;from&lt;/span&gt; scipy.integrate &lt;span style="color: #8b0000;"&gt;import&lt;/span&gt; quad
&lt;span style="color: #8b0000;"&gt;import&lt;/span&gt; numpy &lt;span style="color: #8b0000;"&gt;as&lt;/span&gt; np

x = [0, 0.5, 1, 1.5, 2]
y = [0,    0.1250,    1.0000,    3.3750,    8.0000]

f = interp1d(x, y)

&lt;span style="color: #ff0000; font-weight: bold;"&gt;# numerical trapezoid method&lt;/span&gt;
xfine = np.linspace(0.25, 1.75)
yfine = f(xfine)
&lt;span style="color: #8b0000;"&gt;print&lt;/span&gt; np.trapz(yfine, xfine)

&lt;span style="color: #ff0000; font-weight: bold;"&gt;# quadrature with interpolation&lt;/span&gt;
ans, err = quad(f, 0.25, 1.75)
&lt;span style="color: #8b0000;"&gt;print&lt;/span&gt; ans
&lt;/pre&gt;
&lt;/div&gt;

&lt;pre class="example"&gt;
2.53199187838
2.53125
&lt;/pre&gt;

&lt;p&gt;
These approaches are very similar, and both rely on linear interpolation. The second approach is simpler, and uses fewer lines of code.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-3" class="outline-2"&gt;
&lt;h2 id="sec-3"&gt;&lt;span class="section-number-2"&gt;3&lt;/span&gt; Summary&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-3"&gt;
&lt;p&gt;
trapz and quad are functions for getting integrals. Both can be used with numerical data if interpolation is used. The syntax for the quad and trapz function is different in scipy than in Matlab.
&lt;/p&gt;

&lt;p&gt;
Finally, see this &lt;a href="http://matlab.cheme.cmu.edu/2011/08/30/solving-integral-equations/" &gt;post&lt;/a&gt; for an example of solving an integral equation using quad and fsolve.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Copyright (C) 2013 by John Kitchin. See the &lt;a href="/copying.html"&gt;License&lt;/a&gt; for information about copying.&lt;p&gt;&lt;p&gt;&lt;a href="/org/2013/02/02/On-the-quad-or-trapz'd-in-ChemE-heaven.org"&gt;org-mode source&lt;/a&gt;&lt;p&gt;]]></content:encoded>
    </item>
    <item>
      <title>Integrating equations in python</title>
      <link>http://jkitchin.github.io/blog/2013/01/20/Integrating-equations-in-python</link>
      <pubDate>Sun, 20 Jan 2013 09:00:00 EST</pubDate>
      <category><![CDATA[integration]]></category>
      <category><![CDATA[python]]></category>
      <guid isPermaLink="false">x_Smua6QCafcMbwEEDQEQxOy_cQ=</guid>
      <description>Integrating equations in python</description>
      <content:encoded><![CDATA[



&lt;p&gt;
A common need in engineering calculations is to integrate an equation over some range to determine the total change. For example, say we know the volumetric flow changes with time according to \(d\nu/dt = \alpha t\), where \(\alpha = 1\) L/min and we want to know how much liquid flows into a tank over 10 minutes if the volumetric flowrate is \(\nu_0 = 5\) L/min at \(t=0\). The answer to that question is the value of this integral: \(V = \int_0^{10} \nu_0 + \alpha t dt\). 
&lt;/p&gt;

&lt;div class="org-src-container"&gt;

&lt;pre class="src src-python"&gt;&lt;span style="color: #8b0000;"&gt;import&lt;/span&gt; scipy
&lt;span style="color: #8b0000;"&gt;from&lt;/span&gt; scipy.integrate &lt;span style="color: #8b0000;"&gt;import&lt;/span&gt; quad

nu0 = 5     &lt;span style="color: #ff0000; font-weight: bold;"&gt;# L/min&lt;/span&gt;
alpha = 1.0 &lt;span style="color: #ff0000; font-weight: bold;"&gt;# L/min&lt;/span&gt;
&lt;span style="color: #8b0000;"&gt;def&lt;/span&gt; &lt;span style="color: #8b2323;"&gt;integrand&lt;/span&gt;(t):
    &lt;span style="color: #8b0000;"&gt;return&lt;/span&gt; nu0 + alpha * t

t0 = 0.0
tfinal = 10.0
V, estimated_error = quad(integrand, t0, tfinal)
&lt;span style="color: #8b0000;"&gt;print&lt;/span&gt;(&lt;span style="color: #228b22;"&gt;'{0:1.2f} L flowed into the tank over 10 minutes'&lt;/span&gt;.format(V))
&lt;/pre&gt;
&lt;/div&gt;

&lt;pre class="example"&gt;
100.00 L flowed into the tank over 10 minutes
&lt;/pre&gt;

&lt;p&gt;
That is all there is too it!&lt;/p&gt;
&lt;p&gt;Copyright (C) 2013 by John Kitchin. See the &lt;a href="/copying.html"&gt;License&lt;/a&gt; for information about copying.&lt;p&gt;&lt;p&gt;&lt;a href="/org/2013/01/20/Integrating-equations-in-python.org"&gt;org-mode source&lt;/a&gt;&lt;p&gt;]]></content:encoded>
    </item>
    <item>
      <title>Integrating a batch reactor design equation</title>
      <link>http://jkitchin.github.io/blog/2013/01/06/Integrating-a-batch-reactor-design-equation</link>
      <pubDate>Sun, 06 Jan 2013 09:00:00 EST</pubDate>
      <category><![CDATA[integration]]></category>
      <guid isPermaLink="false">S-ZeHf9XdaSncqKZbrn1BFFx3HE=</guid>
      <description>Integrating a batch reactor design equation</description>
      <content:encoded><![CDATA[


&lt;p&gt;
For a constant volume batch reactor where \(A \rightarrow B\) at a rate of \(-r_A = k C_A^2\), we derive the following design equation for the length of time required to achieve a particular level of conversion :
&lt;/p&gt;

&lt;p&gt;
\(t(X) = \frac{1}{k C_{A0}} \int_{X=0}^X \frac{dX}{(1-X)^2}\)
&lt;/p&gt;

&lt;p&gt;
if \(k = 10^{-3}\) L/mol/s and \(C_{A0}\) = 1 mol/L, estimate the time to achieve 90% conversion.
&lt;/p&gt;

&lt;p&gt;
We could analytically solve the integral and evaluate it, but instead we will numerically evaluate it using scipy.integrate.quad. This function returns two values: the evaluated integral, and an estimate of the absolute error in the answer.
&lt;/p&gt;

&lt;div class="org-src-container"&gt;

&lt;pre class="src src-python"&gt;&lt;span style="color: #8b0000;"&gt;from&lt;/span&gt; scipy.integrate &lt;span style="color: #8b0000;"&gt;import&lt;/span&gt; quad

&lt;span style="color: #8b0000;"&gt;def&lt;/span&gt; &lt;span style="color: #8b2323;"&gt;integrand&lt;/span&gt;(X):
    k = 1.0e-3
    Ca0 = 1.0  &lt;span style="color: #ff0000; font-weight: bold;"&gt;# mol/L&lt;/span&gt;
    &lt;span style="color: #8b0000;"&gt;return&lt;/span&gt; 1./(k*Ca0)*(1./(1-X)**2)

sol, abserr = quad(integrand, 0, 0.9)
&lt;span style="color: #8b0000;"&gt;print&lt;/span&gt; &lt;span style="color: #228b22;"&gt;'t = {0} seconds ({1} hours)'&lt;/span&gt;.format(sol, sol/3600)
&lt;span style="color: #8b0000;"&gt;print&lt;/span&gt; &lt;span style="color: #228b22;"&gt;'Estimated absolute error = {0}'&lt;/span&gt;.format(abserr)
&lt;/pre&gt;
&lt;/div&gt;

&lt;pre class="example"&gt;
t = 9000.0 seconds (2.5 hours)
Estimated absolute error = 2.12203274482e-07
&lt;/pre&gt;


&lt;p&gt;
You can see the estimate error is very small compared to the solution.
&lt;/p&gt;
&lt;p&gt;Copyright (C) 2013 by John Kitchin. See the &lt;a href="/copying.html"&gt;License&lt;/a&gt; for information about copying.&lt;p&gt;&lt;p&gt;&lt;a href="/org/2013/01/06/Integrating-a-batch-reactor-design-equation.org"&gt;org-mode source&lt;/a&gt;&lt;p&gt;]]></content:encoded>
    </item>
  </channel>
</rss>
