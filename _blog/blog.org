* DONE Scoring elfeed articles
  CLOSED: [2017-01-05 Thu 11:18]
  :PROPERTIES:
  :categories: emacs,elfeed
  :date:     2017/01/05 11:18:29
  :updated:  2017/01/05 21:12:13
  :END:

I use [[https://github.com/skeeto/elfeed][elfeed]] to read RSS feeds of scientific journals, python, emacs, and lisp blogs, and the emacs stackexchange feed. Here are the current feeds I follow.

#+BEGIN_SRC emacs-lisp
(mapcar 'list elfeed-feeds)
#+END_SRC

#+RESULTS:
| (http://syndic8.scopus.com/getMessage?registrationId=ADEJAEEKHFESCDEOCDFOAHGSCDHSAKHREFMSADHNJA cmu)              |
| http://feeds.feedburner.com/acs/accacs                                                                            |
| http://feeds.feedburner.com/acs/enfuem                                                                            |
| http://feeds.feedburner.com/acs/esthag                                                                            |
| http://feeds.feedburner.com/acs/jacsat                                                                            |
| http://feeds.feedburner.com/acs/jpcbfk                                                                            |
| http://feeds.feedburner.com/acs/jpccck                                                                            |
| http://feeds.feedburner.com/acs/jpclcd                                                                            |
| http://feeds.feedburner.com/acs/cmatex                                                                            |
| http://feeds.feedburner.com/acs/jctcce                                                                            |
| http://feeds.feedburner.com/acs/jcisd8                                                                            |
| http://feeds.feedburner.com/acs/iecred                                                                            |
| http://feeds.aps.org/rss/recent/prl.xml                                                                           |
| http://feeds.aps.org/rss/recent/prb.xml                                                                           |
| http://www.sciencemag.org/rss/current.xml                                                                         |
| http://feeds.nature.com/nature/rss/current                                                                        |
| http://feeds.nature.com/nmat/rss/current                                                                          |
| http://feeds.nature.com/nchem/rss/current                                                                         |
| http://rss.sciencedirect.com/publication/science/09270256                                                         |
| http://onlinelibrary.wiley.com/rss/journal/10.1002/(ISSN)1521-3773                                                |
| http://scitation.aip.org/rss/content/aip/journal/jcp/latestarticles;jsessionid=6k76xb11z253.x-aip-live-06?fmt=rss |
| (http://planetpython.org/rss20.xml python)                                                                        |
| (http://planet.scipy.org/rss20.xml python)                                                                        |
| (http://planet.emacsen.org/atom.xml emacs)                                                                        |
| http://planet.lisp.org/rss20.xml                                                                                  |
| http://catalysis-preprint-archive.github.io/updates.rss                                                           |
| https://www.cmu.edu/policies/news/rss-feed.rss                                                                    |
| (http://emacs.stackexchange.com/feeds emacs)                                                                      |

I get a lot of articles this way. The current size of the database is:

#+BEGIN_SRC emacs-lisp
(elfeed-db-size)
#+END_SRC

#+RESULTS:
: 79721

Elfeed tells me I have over 300 unread entries to review at the moment.

#+BEGIN_SRC emacs-lisp
(elfeed-search--count-unread)
#+END_SRC

#+RESULTS:
: 341/363:24

To deal with this deluge, I have done a couple of things. I set up some new key-bindings so I can alternate marking entries as read if the titles do not look interesting. These keybindings let me alternate fingers, so they do not get too tired (that really happens some days!).

#+BEGIN_SRC emacs-lisp
;; help me alternate fingers in marking entries as read
(define-key elfeed-search-mode-map (kbd "f") 'elfeed-search-untag-all-unread)
(define-key elfeed-search-mode-map (kbd "j") 'elfeed-search-untag-all-unread)
#+END_SRC

I also set up some auto-tagging of the emacs and python feeds, and setup some custom faces so these tags are highlighted so they are easy to see. Anything highlighted in blue is related to emacs, green is related to python, and pink is related to my department, and I can type s, then the tag to see only those entries.  Here is what my feed looks like:

#+attr_org: :width 600
[[./screenshots/date-05-01-2017-time-08-42-33.png]]



Today I want to explore adding tags to entries to further prioritize them. There is a way to tag entries that is described here: https://github.com/skeeto/elfeed#tag-hooks where you can create patterns to match an entry feed title, url, title or link. Basically, you create a function that takes an entry, amd have it add or remove a tag conditionally.

I want to tag entries that meet certain criteria, for example keywords, and set a tag based on the number of matches. Ideally, one day this would be integrated with machine learning so it could rank entries by other entries I have liked, but today we setup code that will create a score for an entry based on the number of matches, and then tag it so that it will get highlighted for me.  First, we define two custom faces and setup elfeed to use them. I will use two tags: important and relevant. relevant will be for entries that get a score of at least 1, and important for entries that get a score greater than 1.

#+BEGIN_SRC emacs-lisp :results silent
(defface relevant-elfeed-entry
  `((t :background ,(color-lighten-name "orange1" 40)))
  "Marks a relevant Elfeed entry.")

(defface important-elfeed-entry
  `((t :background ,(color-lighten-name "OrangeRed2" 40)))
  "Marks an important Elfeed entry.")

(push '(relevant relevant-elfeed-entry)
      elfeed-search-face-alist)

(push '(important important-elfeed-entry)
      elfeed-search-face-alist)
#+END_SRC

In elfeed, each entry is a structure, and we can access the title and content for matching. Here is an example of a simple scoring function. The idea is just to match patterns, and then add to the score if it matches. This is not as advanced as [[https://www.gnu.org/software/emacs/manual/html_node/gnus/Scoring.html#Scoring][gnus scoring]], but it is a good starting point.

#+BEGIN_SRC emacs-lisp
(defun score-elfeed-entry (entry)
  (let ((title (elfeed-entry-title entry))
	(content (elfeed-deref (elfeed-entry-content entry)))
	(score 0))
    (loop for (pattern n) in '(("alloy" 1)
			       ("machine learning\\|neural" 1)
			       ("database" 1)
			       ("reproducible" 1)
			       ("carbon dioxide\\|CO2" 1)
			       ("oxygen evolution\\|OER\\|electrolysis" 1)
			       ("perovskite\\|polymorph\\|epitax" 1)
			       ("kitchin" 2))
	  if (string-match pattern title)
	  do (incf score n)
	  if (string-match pattern content)
	  do (incf score n))
    (message "%s - %s" title score)

    ;; store score for later in case I ever integrate machine learning
    (setf (elfeed-meta entry :my/score) score)

    (cond
     ((= score 1)
      (elfeed-tag entry 'relevant))
     ((> score 1)
      (elfeed-tag entry 'important)))
    entry))

(add-hook 'elfeed-new-entry-hook 'score-elfeed-entry)
#+END_SRC

#+RESULTS:
| score-elfeed-entry |

Now, new entries automatically get tagged with relevant or important, depending on the score that function gives them, and they get color-coded. Now, the feed looks like this:

#+attr_org: :width 600
[[./screenshots/date-05-01-2017-time-11-10-42.png]]


I saved some bookmarks to see just the important or relevant ones (http://nullprogram.com/blog/2015/12/03/) so I can see new relevant entries with C-x r b and selecting the relevant bookmark. These work from anywhere in Emacs.

#+BEGIN_EXAMPLE
  @6-months-ago +unread +relev  @6-months-ago +unread +relevant
  elfeed @6-months-ago +unread  @6-months-ago +unread +important
#+END_EXAMPLE

I usually access elfeed from a command that shows me everything. Here, I define key-bindings to show me just the important or relevant ones. I could not see a way to get an or in there to show me both of them. These keys make it a one key press to show only these entries, and then get back to the full list.

#+BEGIN_SRC emacs-lisp
(define-key elfeed-search-mode-map (kbd "i")
  (lambda () (interactive)
    (elfeed-search-set-filter "@6-months-ago +unread +important")))

(define-key elfeed-search-mode-map (kbd "v")
  (lambda () (interactive)
    (elfeed-search-set-filter "@6-months-ago +unread +relevant")))

(define-key elfeed-search-mode-map (kbd "c")
  (lambda () (interactive)
    (elfeed-search-set-filter "@6-months-ago +unread")))
#+END_SRC


That summarizes the experiment of the day. There is clearly some room for improvement on the scoring function, e.g. moving the patterns out of the function and into a customizable variable, making the patterns be specific to either the title or content, etc. I am going to try this for a few days and see if it is actually helpful first though.

* DONE Querying a MongoDB bibtex database with Python and emacs-lisp
  CLOSED: [2017-01-15 Sun 10:36]
  :PROPERTIES:
  :categories: database,mongodb,emacs,python
  :date:     2017/01/15 10:36:22
  :updated:  2017/01/15 10:36:22
  :END:
I have been exploring [[http://kitchingroup.cheme.cmu.edu/blog/2017/01/03/Find-stuff-in-org-mode-anywhere/][using databases]] to help with searching my data. In this post we explore using MongoDB for bibtex entries. I am choosing bibtex entries because it is easy to parse bibtex files, I already have a lot of them, and I have several kinds of queries I regularly use. So, they are a good candidate to test out a new database on!

MongoDB is a noSQL database that is pretty easy to use. I installed it from homebrew, and then followed the directions to run the server.

With pymongo you can make a database as easy as this:

#+BEGIN_SRC python :results output org drawer
import bibtexparser

# Read the bibtex file to get entries
with open('../../../Dropbox/bibliography/references.bib', 'r') as bibfile:
    bp = bibtexparser.load(bibfile)
    entries = bp.entries

print("N = ", len(entries))

print(entries[0])

import pymongo
from pymongo import MongoClient
client = MongoClient('localhost', 27017)

# This creates the "entries" collection
db = client['bibtex'].entries

# add each entry
for entry in entries:
    db.insert_one(entry)
#+END_SRC

#+RESULTS:
:RESULTS:
N =  1671
{'keyword': 'test, word', 'year': '2006', 'publisher': 'American Chemical Society (ACS)', 'title': 'The ACS Style Guide', 'ENTRYTYPE': 'book', 'editor': 'Janet S. Dodd', 'address': 'Washington, D.C.', 'ID': '2006-acs-style-guide', 'doi': '10.1021/bk-2006-styg', 'link': 'http://dx.doi.org/10.1021/bk-2006-STYG', 'date_added': 'Wed Apr  1 10:17:54 2015', 'pages': 'nil'}
:END:

That was easy. We have a database with 1671 documents in it, and each document is essentially a dictionary of key-value pairs. You might even argue it was too easy. I didn't specify any structure to the entries at all. No required fields, no validation that the keys are spelled correctly, no validation on the values, e.g. you can see the year looks like a string. The benefit of that is that every entry went in, with no issues. On the other hand, the authors went in as a single string, as did the keywords, which affects our ability to search a little bit later. Note if you run that twice, it will add each entry again, since we do not check if the entry already exists.

A database is only useful though if it is easy to get stuff out of it. So, let's consider some test queries. First we find entries that have years less than 1950. The query is basically a little json bundle that describes a field and condition that we want to match. Here we use a less than operator, ""$lt"The results come back as a list of dictionaries. This is in stark contrast to a SQL query which is an expression in its own declarative language. A query here is a chunk of data that must get converted to code by the server. I am not 100% clear if the less than here is in the string sense or numeric sense, but for years it probably does not matter for a long time.

#+BEGIN_SRC python :results output org drawer
import pymongo
from pymongo import MongoClient
client = MongoClient('localhost', 27017)

db = client['bibtex'].entries

for i, result in enumerate(db.find({"year" : {"$lt": "1950"}})):
    print('{i: 2d}. {author}, {title}, {journal}, {year}.'.format(i=i+1, **result))
#+END_SRC

#+RESULTS:
:RESULTS:
 1. Birch, Francis, Finite Elastic Strain of Cubic Crystals, Phys. Rev., 1947.
 2. Ditchburn, R. W. and Gilmour, J. C., The Vapor Pressures of Monatomic Vapors, Rev. Mod. Phys., 1941.
 3. J. Korringa, On the Calculation of the Energy of a Bloch Wave in a Metal, Physica, 1947.
 4. Nix, F. C. and MacNair, D., The Thermal Expansion of Pure Metals. {II}: Molybdenum, Palladium, Silver, Tantalum, Tungsten, Platinum, and Lead, Phys. Rev., 1942.
:END:


That seems easy enough, and those strings could easily be used as candidates for a selection tool like helm.

How about articles published by myself and my student Jacob Boes? This requires "and" logic. Apparently that is the default, so we just add three queries. One is an exact match on articles, and the other two are case-insensitive regular expression matches.  I guess this has to be done on every document, since there probably is no way to index a regex match! This search was very fast, but it is not clear how fast it would be for a million entries. This matching is necessary because we stored all authors in a single field rather than splitting them into an array. We might still have to match strings for this even in an array since an author might then be "John R. Kitchin", rather than further decomposed into first and last names.

#+BEGIN_SRC python :results output org drawer
import pymongo
from pymongo import MongoClient
client = MongoClient('localhost', 27017)

db = client['bibtex']
entries = db['entries']

for i, result in enumerate(entries.find({"ENTRYTYPE": "article",
                                         "author" : {"$regex": "kitchin", '$options' : 'i'},
                                         "author" : {"$regex": "boes", '$options' : 'i'}})):
    if result.get('doi', None):
        result['doi'] = 'http://dx.doi.org/{doi}'.format(doi=result['doi'])
    else:
        result['doi'] = ''
    print('{i: 2d}. {author}, {title}, {journal}, {year}. {doi}'.format(i=i+1, **result).replace("\n", ""))
#+END_SRC

#+RESULTS:
:RESULTS:
 1. Jacob R. Boes and Peter Kondratyuk and Chunrong Yin and JamesB. Miller and Andrew J. Gellman and John R. Kitchin, Core Level Shifts in {Cu-Pd} Alloys As a Function of BulkComposition and Structure, Surface Science, 2015. http://dx.doi.org/10.1016/j.susc.2015.02.011
 2. Jacob R. Boes and Gamze Gumuslu and James B. Miller and AndrewJ. Gellman and John R. Kitchin, Estimating Bulk-Composition-Dependent \ce{H2} AdsorptionEnergies on \ce{Cu_{x}Pd_{1-x}} Alloy (111) Surfaces, ACS Catalysis, 2015. http://dx.doi.org/10.1021/cs501585k
 3. Jacob R. Boes and Gamze Gumuslu and James B. Miller and AndrewJ. Gellman and John R. Kitchin, Supporting Information: Estimating Bulk-Composition-Dependent\ce{H2} Adsorption Energies on \ce{Cu_{x}Pd_{1-x}} Alloy (111)Surfaces, ACS Catalysis, 2015. http://dx.doi.org/10.1021/cs501585k
 4. G. Gumuslu and P. Kondratyuk and J. R. Boes and B. Morrealeand J. B. Miller and J. R. Kitchin and A. J. Gellman, Correlation of Electronic Structure With Catalytic Activity:\ce{H2}-\ce{D2} Exchange Across \ce{Cu_{x}Pd_{1-x}}Composition Space, ACS Catalysis, 2015. http://dx.doi.org/10.1021/cs501586t
 5. John D. Michael and Ethan L. Demeter and Steven M. Illes andQingqi Fan and Jacob R. Boes and John R. Kitchin, Alkaline Electrolyte and {Fe} Impurity Effects on thePerformance and Active-Phase Structure of {NiOOH} Thin Filmsfor {OER} Catalysis Applications, J. Phys. Chem. C, 2015. http://dx.doi.org/10.1021/acs.jpcc.5b02458
 6. Jacob R. Boes and Mitchell C. Groenenboom and John A. Keithand John R. Kitchin, Neural Network and {Reaxff} Comparison for {Au} Properties, Int. J. Quantum Chem., 2016. http://dx.doi.org/10.1002/qua.25115
 7. Jacob R. Boes and John R. Kitchin, Neural Network Predictions of Oxygen Interactions on a Dynamic Pd Surface, Molecular Simulation, Accepted 12/2016. http://dx.doi.org/10.1080/08927022.2016.1274984
 8. Jacob R. Boes and John R. Kitchin, Modeling Segregation on {AuPd}(111) Surfaces With DensityFunctional Theory and Monte Carlo Simulations, Submitted to J. Phys. Chem. C, 2016.
:END:

We can find out how many different entry types we have, as well as how many distinct keyword entries there are. The documents do not separate the keywords though, so this is just the unique strings of comma-separated keywords values. We would have had to split those in advance to have a list of keywords to search for a specific one beyond string matching. Curiously, in my bibtex entries, these are in a field called "keywords". It appears the bibtex parser may have changed the name to "keyword".

#+BEGIN_SRC python :results output org drawer
import pymongo
from pymongo import MongoClient
client = MongoClient('localhost', 27017)

db = client['bibtex']
entries = db['entries']

print(entries.distinct("ENTRYTYPE"))
print(len(entries.distinct("keyword")))
print(entries.find({"keyword": {"$exists": "true"}})[22]['keyword'])
#+END_SRC

#+RESULTS:
:RESULTS:
['book', 'article', 'techreport', 'phdthesis', 'inproceedings', 'inbook', 'mastersthesis', 'misc', 'incollection']
176
Bildungsw{\"a}rmen, Dichtefunktionalrechnungen, Perowskite, Thermochemie
:END:

** text searching

You can do text search as well. You first have to create an index on one or more fields, and then use the $text and $search operators. Here I made an index on a few fields, and then searched on it. Note that you can only have one text index, so think about it in advance! This simplifies the query a bit, we do not have to use the regex syntax for matching on a field.

#+BEGIN_SRC python :results output org drawer
import pymongo
from pymongo import MongoClient
client = MongoClient('localhost', 27017)

db = client['bibtex']
entries = db['entries']

entries.create_index([('author', pymongo.TEXT),
                      ('title', pymongo.TEXT),
                      ('keyword', pymongo.TEXT)], sparse=True)

for i, result in enumerate(entries.find({"$text" : {"$search": "kitchin", "$search": "boes"}})):
    print('{i: 2d}. {author}, {title}, {journal}, {year}.'.format(i=i, **result).replace("\n", ""))
#+END_SRC

#+RESULTS:
:RESULTS:
 0. G. Gumuslu and P. Kondratyuk and J. R. Boes and B. Morrealeand J. B. Miller and J. R. Kitchin and A. J. Gellman, Correlation of Electronic Structure With Catalytic Activity:\ce{H2}-\ce{D2} Exchange Across \ce{Cu_{x}Pd_{1-x}}Composition Space, ACS Catalysis, 2015.
 1. Jacob R. Boes and Peter Kondratyuk and Chunrong Yin and JamesB. Miller and Andrew J. Gellman and John R. Kitchin, Core Level Shifts in {Cu-Pd} Alloys As a Function of BulkComposition and Structure, Surface Science, 2015.
 2. Jacob R. Boes and Gamze Gumuslu and James B. Miller and AndrewJ. Gellman and John R. Kitchin, Estimating Bulk-Composition-Dependent \ce{H2} AdsorptionEnergies on \ce{Cu_{x}Pd_{1-x}} Alloy (111) Surfaces, ACS Catalysis, 2015.
 3. Jacob R. Boes and John R. Kitchin, Neural Network Predictions of Oxygen Interactions on a Dynamic Pd Surface, Molecular Simulation, Accepted 12/2016.
 4. Jacob R. Boes and John R. Kitchin, Modeling Segregation on {AuPd}(111) Surfaces With DensityFunctional Theory and Monte Carlo Simulations, Submitted to J. Phys. Chem. C, 2016.
 5. Jacob R. Boes and Gamze Gumuslu and James B. Miller and AndrewJ. Gellman and John R. Kitchin, Supporting Information: Estimating Bulk-Composition-Dependent\ce{H2} Adsorption Energies on \ce{Cu_{x}Pd_{1-x}} Alloy (111)Surfaces, ACS Catalysis, 2015.
 6. John D. Michael and Ethan L. Demeter and Steven M. Illes andQingqi Fan and Jacob R. Boes and John R. Kitchin, Alkaline Electrolyte and {Fe} Impurity Effects on thePerformance and Active-Phase Structure of {NiOOH} Thin Filmsfor {OER} Catalysis Applications, J. Phys. Chem. C, 2015.
 7. Jacob R. Boes and Mitchell C. Groenenboom and John A. Keithand John R. Kitchin, Neural Network and {Reaxff} Comparison for {Au} Properties, Int. J. Quantum Chem., 2016.
:END:

We can use this to search for documents with orgmode in a keyword or title too.

#+BEGIN_SRC python :results output org drawer
import pymongo
from pymongo import MongoClient
client = MongoClient('localhost', 27017)

db = client['bibtex']
entries = db['entries']

entries.create_index([('author', pymongo.TEXT),
                      ('title', pymongo.TEXT),
                      ('keyword', pymongo.TEXT)], sparse=True)

for i, result in enumerate(entries.find({"$text" : {"$search": "orgmode"}})):
    print('{i: 2d}. {author}, {title}, {journal}, {year}.'.format(i=i, **result).replace("\n", ""))
#+END_SRC

#+RESULTS:
:RESULTS:
 0. John R. Kitchin, Data Sharing in Surface Science, Surface Science, 2016.
 1. Zhongnan Xu and John R. Kitchin, Probing the Coverage Dependence of Site and AdsorbateConfigurational Correlations on (111) Surfaces of LateTransition Metals, J. Phys. Chem. C, 2014.
 2. Xu, Zhongnan and Rossmeisl, Jan and Kitchin, John R., A Linear Response {DFT}+{U} Study of Trends in the OxygenEvolution Activity of Transition Metal Rutile Dioxides, The Journal of Physical Chemistry C, 2015.
 3. Prateek Mehta and Paul A. Salvador and John R. Kitchin, Identifying Potential \ce{BO2} Oxide Polymorphs for EpitaxialGrowth Candidates, ACS Appl. Mater. Interfaces, 2015.
 4. Xu, Zhongnan and Joshi, Yogesh V. and Raman, Sumathy andKitchin, John R., Accurate Electronic and Chemical Properties of 3d TransitionMetal Oxides Using a Calculated Linear Response {U} and a {DFT+ U(V)} Method, The Journal of Chemical Physics, 2015.
 5. Zhongnan Xu and John R. Kitchin, Relationships Between the Surface Electronic and ChemicalProperties of Doped 4d and 5d Late Transition Metal Dioxides, The Journal of Chemical Physics, 2015.
 6. Zhongnan Xu and John R Kitchin, Tuning Oxide Activity Through Modification of the Crystal andElectronic Structure: From Strain To Potential Polymorphs, Phys. Chem. Chem. Phys., 2015.
 7. Jacob R. Boes and Gamze Gumuslu and James B. Miller and AndrewJ. Gellman and John R. Kitchin, Supporting Information: Estimating Bulk-Composition-Dependent\ce{H2} Adsorption Energies on \ce{Cu_{x}Pd_{1-x}} Alloy (111)Surfaces, ACS Catalysis, 2015.
 8. Kitchin, John R., Examples of Effective Data Sharing in Scientific Publishing, ACS Catalysis, 2015.
 9. Curnan, Matthew T. and Kitchin, John R., Effects of Concentration, Crystal Structure, Magnetism, andElectronic Structure Method on First-Principles Oxygen VacancyFormation Energy Trends in Perovskites, The Journal of Physical Chemistry C, 2014.
 10. Kitchin, John R. and Van Gulick, Ana E. and Zilinski, Lisa D., Automating Data Sharing Through Authoring Tools, International Journal on Digital Libraries, 2016.
 11. Jacob R. Boes and Gamze Gumuslu and James B. Miller and AndrewJ. Gellman and John R. Kitchin, Estimating Bulk-Composition-Dependent \ce{H2} AdsorptionEnergies on \ce{Cu_{x}Pd_{1-x}} Alloy (111) Surfaces, ACS Catalysis, 2015.
 12. Zhongnan Xu and John R. Kitchin, Relating the Electronic Structure and Reactivity of the 3dTransition Metal Monoxide Surfaces, Catalysis Communications, 2014.
 13. Spencer D. Miller and Vladimir V. Pushkarev and AndrewJ. Gellman and John R. Kitchin, Simulating Temperature Programmed Desorption of Oxygen on{P}t(111) Using {DFT} Derived Coverage Dependent DesorptionBarriers, Topics in Catalysis, 2014.
 14. Hallenbeck, Alexander P. and Kitchin, John R., Effects of \ce{O_2} and \ce{SO_2} on the Capture Capacity of aPrimary-Amine Based Polymeric \ce{CO_2} Sorbent, Industrial \& Engineering Chemistry Research, 2013.
:END:

** Querying from emacs-lisp

It is hard to get too excited about this if it is not easy to query from emacs and get data in a form we can use in emacs ;) The json library allows us to convert lisp data structures to json pretty easily. For example:

#+BEGIN_SRC emacs-lisp
(require 'json)

(json-encode '((ENTRYTYPE . article)
	       (author . (($regex . kitchin)
			  ($options . i)))
	       (author . (($regex . boes)
			  ($options . i)))))
#+END_SRC

#+RESULTS:
: {"ENTRYTYPE":"article","author":{"$regex":"kitchin","$options":"i"},"author":{"$regex":"boes","$options":"i"}}

So, we can use an a-list syntax to build up the query. Then we can send it to mongo using mongoexport that will return a json string that we can read back into emacs to get lisp data. Here is an example that returns a query. We print the first element here.

#+BEGIN_SRC emacs-lisp
(pp
 (aref (json-read-from-string
	(shell-command-to-string
	 (format "mongoexport --quiet --jsonArray -d bibtex -c entries -q '%s'"
		 (json-encode '((ENTRYTYPE . article)
				(author . (($regex . kitchin)
					   ($options . i)))
				(author . (($regex . boes)
					   ($options . i))))))))
       0))
#+END_SRC

#+RESULTS:
#+begin_example
((_id
  ($oid . "5878d9644c114f59fe86cb36"))
 (author . "Jacob R. Boes and Peter Kondratyuk and Chunrong Yin and James\nB. Miller and Andrew J. Gellman and John R. Kitchin")
 (year . "2015")
 (title . "Core Level Shifts in {Cu-Pd} Alloys As a Function of Bulk\nComposition and Structure")
 (ENTRYTYPE . "article")
 (ID . "boes-2015-core-cu")
 (keyword . "DESC0004031, early-career")
 (volume . "640")
 (doi . "10.1016/j.susc.2015.02.011")
 (link . "http://dx.doi.org/10.1016/j.susc.2015.02.011")
 (issn . "0039-6028")
 (journal . "Surface Science")
 (pages . "127-132"))
#+end_example

That is pretty sweet, we get a lisp data structure we can use. We can wrap that into a reasonable looking function here:

#+BEGIN_SRC emacs-lisp
(defun mongo-find (db collection query)
  (json-read-from-string
   (shell-command-to-string
    (format "mongoexport --quiet --jsonArray -d %s -c %s -q '%s'"
	    db collection (json-encode query)))))
#+END_SRC

#+RESULTS:
: mongo-find

Now we can use the function to query the database, and then format the results. Here we look at the example of articles with authors that match "kitchin" and "boes".

#+BEGIN_SRC emacs-lisp
(loop for counter from 1 for entry across
      (mongo-find "bibtex" "entries" '((ENTRYTYPE . article)
				       (author . (($regex . kitchin)
						  ($options . i)))
				       (author . (($regex . boes)
						  ($options . i)))))
      do
      (setq entry (append `(,(cons "counter" counter)) entry))
      ;; make sure we have a doi field.
      (if (assoc 'doi entry)
	  (push (cons "doi" (format "http://dx.doi.org/%s" (cdr (assoc 'doi entry)))) entry)
	(push (cons "doi" "") entry))
      concat
      (concat (replace-regexp-in-string
	       "\n" " "
	       (s-format "${counter}. ${author}, ${title} (${year}). ${doi}"
			 'aget entry)) "\n"))
#+END_SRC

#+RESULTS:
: 1. Jacob R. Boes and Peter Kondratyuk and Chunrong Yin and James B. Miller and Andrew J. Gellman and John R. Kitchin, Core Level Shifts in {Cu-Pd} Alloys As a Function of Bulk Composition and Structure (2015). http://dx.doi.org/10.1016/j.susc.2015.02.011
: 2. Jacob R. Boes and Gamze Gumuslu and James B. Miller and Andrew J. Gellman and John R. Kitchin, Estimating Bulk-Composition-Dependent \ce{H2} Adsorption Energies on \ce{Cu_{x}Pd_{1-x}} Alloy (111) Surfaces (2015). http://dx.doi.org/10.1021/cs501585k
: 3. Jacob R. Boes and Gamze Gumuslu and James B. Miller and Andrew J. Gellman and John R. Kitchin, Supporting Information: Estimating Bulk-Composition-Dependent \ce{H2} Adsorption Energies on \ce{Cu_{x}Pd_{1-x}} Alloy (111) Surfaces (2015). http://dx.doi.org/10.1021/cs501585k
: 4. G. Gumuslu and P. Kondratyuk and J. R. Boes and B. Morreale and J. B. Miller and J. R. Kitchin and A. J. Gellman, Correlation of Electronic Structure With Catalytic Activity: \ce{H2}-\ce{D2} Exchange Across \ce{Cu_{x}Pd_{1-x}} Composition Space (2015). http://dx.doi.org/10.1021/cs501586t
: 5. John D. Michael and Ethan L. Demeter and Steven M. Illes and Qingqi Fan and Jacob R. Boes and John R. Kitchin, Alkaline Electrolyte and {Fe} Impurity Effects on the Performance and Active-Phase Structure of {NiOOH} Thin Films for {OER} Catalysis Applications (2015). http://dx.doi.org/10.1021/acs.jpcc.5b02458
: 6. Jacob R. Boes and Mitchell C. Groenenboom and John A. Keith and John R. Kitchin, Neural Network and {Reaxff} Comparison for {Au} Properties (2016). http://dx.doi.org/10.1002/qua.25115
: 7. Jacob R. Boes and John R. Kitchin, Neural Network Predictions of Oxygen Interactions on a Dynamic Pd Surface (Accepted 12/2016). http://dx.doi.org/10.1080/08927022.2016.1274984
: 8. Jacob R. Boes and John R. Kitchin, Modeling Segregation on {AuPd}(111) Surfaces With Density Functional Theory and Monte Carlo Simulations (2016).

Wow, that looks like a pretty lispy way to query the database and use the results. It is probably pretty easy to do similar things for inserting and updating documents. I will save that for another day.

** Summary thoughts

This is not an exhaustive study of Mongo for a bibtex database. It does illustrate that it is potentially useful. Imagine a group of users can enter bibtex entries, and then share them through a central server. Or you query the server for entries and then select them using helm/ivy. That is probably faster than parsing large bibtex files (note, in org-ref I already cache the files in parsed form for performance reasons!).

It would make sense to split the authors, and keywords in another version of this database. It also could make sense to have a field that is the bibtex string, and to do text search on that string. That way you get everything in the entry for searching, and an easy way to generate bibtex files without having to reconstruct them.

It is especially interesting to run the queries through emacs-lisp since we get the benefit of editing lisp code while writing the query, e.g. parenthesis navigation, less quoting, etc... and we get back lisp data that can be used to construct helm/ivy queries, or other emacs things. That makes this look competitive with emacsql at least for the syntax. I predict that there will be more posts on this in the future.
* DONE A simple emacs-lisp interface to CRUD operations in mongodb
  CLOSED: [2017-01-16 Mon 09:44]
  :PROPERTIES:
  :categories: database,mongodb,emacs,emacslisp
  :date:     2017/01/16 09:44:16
  :updated:  2017/01/16 09:44:16
  :END:

In this [[http://kitchingroup.cheme.cmu.edu/blog/2017/01/15/Querying-a-MongoDB-bibtex-database-with-Python-and-emacs-lisp/][post]] I showed that MongoDB is pretty easy to use for simple database applications. I showed a way to get data out of the database that is native to Emacs, but to use Mongo in emacs applications comfortably, it would be really helpful to be able to create, read, update and delete (CRUD) entries. There is a minimal interface to mongodb for emacs-lisp here: https://github.com/m2ym/mongo-el. From what I can see, it seems limited to simple, single queries, and it is written with advanced features of emacs-lisp I do not understand enough to extend it. In the last post, I showed an easy way to use mongoexport to get data from a query out of a mongo database. Here I explore a similar approach to round out the CRUD (create, read, update and delete) operations for using emacs-lisp to work with mongodb. This will enable Emacs to easily use MongoDB in applications.

We use the mongo cli with the --eval option, which allows you to run commands on the database. The basic idea is to generate the json we need from a lisp data structure, and use that json in mongo commands as needed. This sounds simple, but below you will see there are plenty of corners to take care of.

The goal here is to get something that is pretty functional. It will not be able to support all the capabilities of MongoDB and the options available in the cli.

** Inserting entries

Here we insert a document into the contacts collection of the contacts database. As in the Python example we considered earlier, this database is automatically created when we run this command.

#+BEGIN_SRC emacs-lisp
(require 'json))
(let* ((json (json-encode '((first-name . "John")
			    (last-name . "Kitchin")
			    (email . "jkitchin@cmu.edu"))))
       (cmd (format "mongo 127.0.0.1/contacts --quiet --eval 'db.contacts.insert(%s)'"
		    json)))
  (shell-command-to-string cmd))
#+END_SRC

#+RESULTS:
: json

Here is a function we can use for inserting, and as you can see it works for multiple inserts too. There is a limit on how long the json string can be for this, so you cannot add too many entries at once with this. I do not know what the limit is, and suspect it is related to using a shell command. When this succeeds there is data returned about what happened, which we try to get in lisp form. Also, I noticed I had to do a little bit of escaping, especially for entries containing a single quote, which messes up the quoting on the shell command, and for non-ascii characters which the shell did not handle well. Maybe this could be avoided with a file-based approach, or if we used a pipe to a process.

#+BEGIN_SRC emacs-lisp
(defun mongo-insert (db collection document)
  "Insert into DB.COLLECTION the DOCUMENT.
DOCUMENT will be some lisp structure that is converted to json."
  ;; we have to escape quote any single quotes. This came from
  ;; http://stackoverflow.com/questions/1250079/how-to-escape-single-quotes-within-single-quoted-strings
  (let* ((json (replace-regexp-in-string "'" "'\"'\"'" (json-encode document)))
	 ;; it seems utf-8 characters may cause issues. Let's just remove them.
	 (json (replace-regexp-in-string "[^[:ascii:]]" "" json))
	 (cmd (format "mongo %s --quiet --eval 'db.%s.insert(%s)'"
		      db collection
		      json))
	 (output (shell-command-to-string cmd)))
    (cond
     ((string-match "BulkWriteResult(" output)
      (json-read-from-string (substring output 16 -2)))
     ((string-match "WriteResult(" output)
      (json-read-from-string (substring output 12 -2)))
     (t
      output))))
#+END_SRC

#+RESULTS:
: mongo-insert

Here it is in action.
#+BEGIN_SRC emacs-lisp
(mongo-insert "contacts" "contacts"
	      '(((first-name . "John")
		 (last-name . "Kitchin")
		 (email . "jkitchin@cmu.edu"))
		((first-name . "Someone")
		 (last-name . "Else")
		 ("email" . "someone@out.there"))))
#+END_SRC

#+RESULTS:
: ((writeErrors . []) (writeConcernErrors . []) (nInserted . 2) (nUpserted . 0) (nMatched . 0) (nModified . 0) (nRemoved . 0) (upserted . []))

Seems like an ok way to get data from Emacs into a Mongo DB, and we get lisp data returned telling us what happened.

** Finding a document

To update documents we need to find them. We would like to find a document by the _id, but we have a small dilemma. The json we need for that needs to look like: {"_id": ObjectId("587babfaef131d0d4603b3ad")}, where the ObjectId is not quoted. The json library does not seem to be able to do that. So, we have to modify our find code to do this. This is possible by manipulating the json string after it is generated with regular expression replacement. It feels hacky, and hopefully there are not many more examples of that. If there are, we will need another approach to generating the json data. Here is the modified find function, also with the projection option. Here is another place we have to tread somewhat lightly with the _id, in this case we have to requote it so that it can be read by emacs. It might make sense to just replace it with the quoted _id string, rather than the ObjectId call. Time will tell.

Here we create two helper functions to unquote input, and requote output. We also need some code to make an array of all the results, and put commas between all the results so that we end up with valid json in the output.

#+BEGIN_SRC emacs-lisp
(defun mongo-unquote-query (query)
  "Json encodes QUERY, and unquotes any ObjectId calls.

We don't have syntax for the ObjectId call that mongo wants in
 lisp, so a query has to look like this:
'((_id .  \"ObjectId(\"587babfaef131d0d4603b3ad\")\"))

Mongo can't have the quotes around the call, so this function
removes them.
"
  (replace-regexp-in-string "\"\\(ObjectID(\\\\\"\\(.*?\\)\\\\\")\\)\""
			    "ObjectId(\"\\2\")"
			    (json-encode query)))

(defun mongo-requote-output (output)
  "Adds quotes around ObjectId in OUTPUT.
When mongo outputs json, it has unquoted ObjectIds in it that
emacs cannot interpret as json. "
  (replace-regexp-in-string
   "ObjectId(\"\\(.*?\\)\")"
   "\"ObjectId(\\\\\"\\1\\\\\")\""
   output))

(defun mongo-find (db collection query &optional projection)
  (let* ((query-json (mongo-unquote-query query))
	 (projection-json
	  (and projection (json-encode projection)))
	 (output (mongo-requote-output
		  ;; add [] to make an array of output in json,
		  ;; and separate results by a comma
		  (concat "["
			  (replace-regexp-in-string
			   "\n" ""
			   (shell-command-to-string
			    (format "mongo %s --quiet --eval 'db.%s.find(%s).forEach(function(myDoc) { printjsononeline(myDoc); print( \",\"); })'"
				    db collection
				    (if projection
					(format "%s, %s" query-json projection-json)
				      query-json))))
			  "]"))))
    (json-read-from-string output)))
#+END_SRC

#+RESULTS:
: mongo-find

So, finally we can run something like this:

#+BEGIN_SRC emacs-lisp
(mongo-find "contacts" "contacts" '((email . "someone@out.there")))
#+END_SRC

#+RESULTS:
: [((_id . "ObjectId(\"587c166cdfcd649d3acf99fd\")") (first-name . "Someone") (last-name . "Else") (email . "someone@out.there")) ((_id . "ObjectId(\"587c16ad410565dd4c16c748\")") (first-name . "Someone") (last-name . "Else") (email . "someone@out.there")) ((_id . "ObjectId(\"587c17550e586b4f8df21de0\")") (first-name . "Someone") (last-name . "Else") (email . "someone@out.there")) ((_id . "ObjectId(\"587c1764d75279a55ffec483\")") (first-name . "Someone") (last-name . "Else") (email . "someone@out.there")) ((_id . "ObjectId(\"587c17743281f1e9d5054396\")") (first-name . "Someone") (last-name . "Else") (email . "someone@out.there")) ((_id . "ObjectId(\"587c178ad92706d2bd5a6e3c\")") (first-name . "Someone") (last-name . "Else") (email . "someone@out.there")) ((_id . "ObjectId(\"587c1794756bb2bd0f0ac499\")") (first-name . "Someone") (last-name . "Else") (email . "someone@out.there"))]

Here is an example usage with a projection that returns only the information you want, in this case, just the id.

#+BEGIN_SRC emacs-lisp
(mongo-find "contacts" "contacts" '((email . "someone@out.there"))
	    '((_id . 1)))
#+END_SRC

#+RESULTS:
: [((_id . "ObjectId(\"587c166cdfcd649d3acf99fd\")")) ((_id . "ObjectId(\"587c16ad410565dd4c16c748\")")) ((_id . "ObjectId(\"587c17550e586b4f8df21de0\")")) ((_id . "ObjectId(\"587c1764d75279a55ffec483\")")) ((_id . "ObjectId(\"587c17743281f1e9d5054396\")")) ((_id . "ObjectId(\"587c178ad92706d2bd5a6e3c\")")) ((_id . "ObjectId(\"587c1794756bb2bd0f0ac499\")"))]

** Updating an entry

Ok, back to the update. To make sure that we update exactly the document we want, we will use the document _id. First, we define an update command.

#+BEGIN_SRC emacs-lisp
(defun mongo-update (db collection query $set)
  "In DB.COLLECTION update records matching QUERY with the contents of $SET."
  (let* ((query-json (mongo-encode-query query))
	 ($set-json (mongo-encode-query $set))
	 (cmd (format "mongo %s --quiet --eval 'db.%s.update(%s, %s)'"
		      db collection
		      query-json $set-json))
	 (output (shell-command-to-string cmd)))
    (if (string-match "WriteResult(" output)
	(json-read-from-string
	 (substring output 12 -2))
      output)))
#+END_SRC

#+RESULTS:
: mongo-update

First a reminder of what is in this record.
#+BEGIN_SRC emacs-lisp
(mongo-find "contacts" "contacts" '((_id . "ObjectId(\"587c16ad410565dd4c16c748\")")))
#+END_SRC

#+RESULTS:
: [((_id . "ObjectId(\"587c16ad410565dd4c16c748\")") (first-name . "Someone") (last-name . "Else") (email . "someone@out.there"))]

Here we set the email field to a new address. Without $set, the whole document gets replaced.

#+BEGIN_SRC emacs-lisp
(mongo-update "contacts" "contacts"
	      '((_id . "ObjectId(\"587c16ad410565dd4c16c748\")"))
	      '(($set . ((email . "someone@out.there.com")))))
#+END_SRC

#+RESULTS:
: ((nMatched . 1) (nUpserted . 0) (nModified . 1))

Finally, let's see the document again to verify it is modified.

#+BEGIN_SRC emacs-lisp
(mongo-find "contacts" "contacts" '((_id . "ObjectId(\"587c16ad410565dd4c16c748\")")))
#+END_SRC

#+RESULTS:
: [((_id . "ObjectId(\"587c16ad410565dd4c16c748\")") (first-name . "Someone") (last-name . "Else") (email . "someone@out.there.com"))]

Looks good, you can see it got changed. There is a potential gotcha though. This next command looks like it should do the same thing, but it does not. The whole document gets replaced!

#+BEGIN_SRC emacs-lisp
(mongo-update "contacts" "contacts"
	      '((_id . "ObjectId(\"587c16ad410565dd4c16c748\")"))
	      '((email . "someone@out.there.com")))
#+END_SRC

#+RESULTS:
: ((nMatched . 1) (nUpserted . 0) (nModified . 1))

#+BEGIN_SRC emacs-lisp
(mongo-find "contacts" "contacts" '((_id . "ObjectId(\"587c16ad410565dd4c16c748\")")))
#+END_SRC

#+RESULTS:
: [((_id . "ObjectId(\"587c16ad410565dd4c16c748\")") (email . "someone@out.there.com"))]

Do not forget the $set operator if you just want to update some fields!

** Deleting a document

Next, let's get a delete function. I will only implement the deleteMany function here since you can give it a document id to delete only one, and usually I would want to delete all documents that meet a criteria anyway.

#+BEGIN_SRC emacs-lisp
(defun mongo-deleteMany (db collection filter)
  "Delete records in DB.COLLECTION matched by FILTER.
TODO: add write concern."
  (let* ((filter-json (mongo-encode-query filter))
	 (cmd (format "mongo %s --quiet --eval 'db.%s.deleteMany(%s)'"
		      db collection
		      filter-json))
	 (output (shell-command-to-string cmd)))
    (json-read-from-string output)))
#+END_SRC

#+RESULTS:
: mongo-deleteMany

Since we borked that last document, let's just delete it.

#+BEGIN_SRC emacs-lisp
(mongo-deleteMany "contacts" "contacts" '((_id . "ObjectId(\"587be3fa6009a569a277b680\")")))
#+END_SRC

#+RESULTS:
: ((acknowledged . t) (deletedCount . 0))

** Generic commands

We may want some flexibility to run collection commands.  The most generic command will simply be to write the shell-command completely. We can keep a little syntax by encapsulating most of the boilerplate though. Here is a function for that.

#+BEGIN_SRC emacs-lisp
(defun mongo-cmd (db collection cmd &rest args)
  "In DB.COLLECTION run CMD.
ARGS if present will be used to format CMD."
  (shell-command-to-string
   (format "mongo %s --quiet --eval 'db.%s.%s'"
	   db collection
	   (apply #'format cmd args))))
#+END_SRC

#+RESULTS:
: mongo-cmd

We can get the number of documents with this:

#+BEGIN_SRC emacs-lisp
(mongo-cmd "contacts" "contacts" "count()")
#+END_SRC

#+RESULTS:
: 4341

Or run a more sophisticated command with arguments like this.

#+BEGIN_SRC emacs-lisp
(mongo-cmd "contacts" "contacts" "explain().remove(%s)" (json-encode '(("category" . "enemy"))))
#+END_SRC

#+RESULTS:
#+begin_example
{
	"queryPlanner" : {
		"plannerVersion" : 1,
		"namespace" : "contacts.contacts",
		"indexFilterSet" : false,
		"parsedQuery" : {
			"category" : {
				"$eq" : "enemy"
			}
		},
		"winningPlan" : {
			"stage" : "DELETE",
			"inputStage" : {
				"stage" : "COLLSCAN",
				"filter" : {
					"category" : {
						"$eq" : "enemy"
					}
				},
				"direction" : "forward"
			}
		},
		"rejectedPlans" : [ ]
	},
	"serverInfo" : {
		"host" : "Johns-MacBook-Air.local",
		"port" : 27017,
		"version" : "3.4.1",
		"gitVersion" : "5e103c4f5583e2566a45d740225dc250baacfbd7"
	},
	"ok" : 1
}
#+end_example

Or, drop the collection with:

#+BEGIN_SRC emacs-lisp
(mongo-cmd "contacts" "contacts" "drop()")
#+END_SRC

#+RESULTS:
: true

All gone! Note, we do not try to handle the output of any of those, and they are returned as strings.

** A MongoDB contacts database

Now, let's re-populate it for real. I store my contacts in a variable called "contacts" as a list of a descriptive string and then cons cells. These are actually harvested from a set of org-files. It is way to slow to parse these files each time, so I keep the contacts cached in memory and only update them if a file changes.

#+BEGIN_SRC emacs-lisp
(length contacts)
#+END_SRC

#+RESULTS:
: 6047

There are over 6000 contacts. Let's put them in a MongoDB.

Here is a limitation of our approach. This will not work because the generated shell command ends up being too long for the shell.

#+BEGIN_SRC emacs-lisp
(mongo-insert "contacts" "contacts"
	      (loop for contact in contacts
		    collect
		    (append `((desc . ,(car contact))) (cdr contact))))
#+END_SRC

#+RESULTS:

So, we do them one at time here:

#+BEGIN_SRC emacs-lisp
(let ((ct (current-time)))
  (loop for contact in contacts
	do
	(let ((output (mongo-insert "contacts" "contacts"
				    (append `((desc . ,(car contact))) (cdr contact)))))
	  (unless (= 1 (cdr (assoc 'nInserted output)))
	    (warn "error: %S for %S" (cdr (assoc 'nInserted output)) contact))))
  (message "Elapsed time %.02f seconds" (float-time (time-since ct))))
#+END_SRC

#+RESULTS:
: Elapsed time 762.95 seconds

That took a little over 10 minutes to add. That seems long to me. This next step confirms that they were added.

#+BEGIN_SRC emacs-lisp
(mongo-cmd "contacts" "contacts" "count()")
#+END_SRC

#+RESULTS:
: 6047

Next we will compare some timing of finding data in the database vs looping through the cached contacts. Here is a timing macro to measure how long it takes to run a bit of code.

#+BEGIN_SRC emacs-lisp
;; http://stackoverflow.com/questions/23622296/emacs-timing-execution-of-function-calls-in-emacs-lisp
(defmacro measure-time (&rest body)
  "Measure the time it takes to evaluate BODY."
  `(let ((time (current-time)))
     ,@body
     (message "%.06f seconds elapsed" (float-time (time-since time)))))
#+END_SRC

#+RESULTS:
: measure-time

Here is the old way I would extract data. Many contacts I have are academics, and I have stored their academic ranks in each contact.

#+BEGIN_SRC emacs-lisp
(loop for contact in contacts
      if (string= "Professor" (cdr (assoc "RANK" (cdr contact))))
      collect contact into professors
      if (string= "Associate Professor" (cdr (assoc "RANK" (cdr contact))))
      collect contact into associate-professors
      if (string= "Assistant Professor" (cdr (assoc "RANK" (cdr contact))))
      collect contact into assistant-professors
      finally return `(("Assistant Professor" ,(length assistant-professors))
		       ("Associate Professor" ,(length associate-professors))
		       ("Professor" ,(length professors))))
#+END_SRC

#+RESULTS:
| Assistant Professor | 313 |
| Associate Professor | 283 |
| Professor           | 879 |

How long did it take to do that?

#+BEGIN_SRC emacs-lisp
(measure-time
 (loop for contact in contacts
       if (string= "Professor" (cdr (assoc "RANK" (cdr contact))))
       collect contact into professors
       if (string= "Associate Professor" (cdr (assoc "RANK" (cdr contact))))
       collect contact into associate-professors
       if (string= "Assistant Professor" (cdr (assoc "RANK" (cdr contact))))
       collect contact into assistant-professors
       finally return (list (length assistant-professors)
			    (length associate-professors)
			    (length professors))))
#+END_SRC

#+RESULTS:
: 0.008772 seconds elapsed

Not long at all! Comparatively, it is very slow to get this information out of the mongodb, although considerably less code is required. That might not be surprising, considering the json parsing that has to get done here.

Here is the equivalent code to extract that data from the database.

#+BEGIN_SRC emacs-lisp
(loop for rank in '("Assistant Professor" "Associate Professor" "Professor")
       collect (list rank (length (mongo-find "contacts" "contacts"
					      `((RANK . ,rank))))))
#+END_SRC

#+RESULTS:
| Assistant Professor | 313 |
| Associate Professor | 283 |
| Professor           | 879 |

It is comparatively slow to do this. This requires three json parses, and profiling indicates that alot of the work is done in parsing the json.

#+BEGIN_SRC emacs-lisp
(measure-time
 (loop for rank in '("Assistant Professor" "Associate Professor" "Professor")
       collect (list rank (length (mongo-find "contacts" "contacts"
					      `((RANK . ,rank)))))))
#+END_SRC

#+RESULTS:
: 1.914817 seconds elapsed

Here is smarter way to do it that avoids the json parsing.

#+BEGIN_SRC emacs-lisp
(loop for rank in '("Assistant Professor" "Associate Professor" "Professor")
      collect (list rank (mongo-cmd "contacts" "contacts" "count(%s)"
				    (json-encode `((RANK . ,rank))))))
#+END_SRC

#+RESULTS:
| Assistant Professor | 313 |
| Associate Professor | 283 |
| Professor           | 879 |

And you can see here it is about 10 times faster, but not nearly as fast as running the lisp code on the cache.

#+BEGIN_SRC emacs-lisp
(measure-time
 (loop for rank in '("Assistant Professor" "Associate Professor" "Professor")
       collect (list rank (mongo-cmd "contacts" "contacts" "count(%s)"
				     (json-encode `((RANK . ,rank)))))))
#+END_SRC

#+RESULTS:
: 0.349413 seconds elapsed

This is how you might integrate this into a completion command:

#+BEGIN_SRC emacs-lisp
(ivy-read "choose: "
	  (loop for c across (mongo-find "contacts" "contacts" "")
		collect
		(list (cdr (assoc 'desc c)) c)))
#+END_SRC

This is basically unusable though, because it takes so long to generate the candidates (over six seconds).

#+BEGIN_SRC emacs-lisp
(measure-time
 (loop for c across (mongo-find "contacts" "contacts" "")
       collect
       (list (cdr (assoc 'desc c)) c)))
#+END_SRC

#+RESULTS:
: 6.228225 seconds elapsed

We can get back to usable by making the database do more work for us. Here, we simply make the database print a list of cons cells that we can read into lisp. We have to use a javascript function, with some escaping and quoting. The escaping was necessary because there is some bad data in the email field that messed up the cons cells, e.g. some things like "name" <email> with nested single and double quoting, etc., and the quoting was necessary to get cons cells of the form ("desc" . "email"), and finally we wrap them in parentheses and read back the list of cons cells. At about a quarter of a second, this is very usable to get a list of over 6000 candidates. It is still many times slower than working on the contacts list in memory though. I am not a super fan of the one-line javascript, and if it was much more complicated than this another strategy would probably be desirable.

#+BEGIN_SRC emacs-lisp
(measure-time
 (read
  (concat
   "("
   (shell-command-to-string "mongo contacts --quiet --eval 'db.contacts.find().forEach(function (doc) {print(\"(\\\"\" + doc.desc + \"\\\" . \\\"\" + escape(doc.EMAIL) +\"\\\")\");})'")
   ")")))
#+END_SRC

#+RESULTS:
: 0.284730 seconds elapsed

** Text searching

Finally, let us make a text index to make searching easy. This allows us a very flexible search where we do not have to specify what field or use regular expressions. We setup the index on all the fields, so we can find entries that match even on fields that do not exist in all documents.

#+BEGIN_SRC emacs-lisp
(mongo-cmd "contacts" "contacts" "createIndex(%s)" (json-encode '(("$**" . "text"))))
#+END_SRC

#+RESULTS:
: {
: 	"createdCollectionAutomatically" : false,
: 	"numIndexesBefore" : 1,
: 	"numIndexesAfter" : 2,
: 	"ok" : 1
: }

Now, let's use that to find the GOOGLE-SCHOLAR url of contacts matching the following query.

#+BEGIN_SRC emacs-lisp :results code
(mongo-find "contacts" "contacts" '(($text . (($search . "\"Carnegie Mellon\"")))
				    ($text . (($search . "\"John Kitchin\""))))
	    '((GOOGLE-SCHOLAR . 1) (_id . 0)))
#+END_SRC

#+RESULTS:
#+BEGIN_SRC emacs-lisp
[((GOOGLE-SCHOLAR . "https://scholar.google.com/citations?hl=en&user=jD_4h7sAAAAJ"))
 nil nil]
#+END_SRC

So, you can see there were three contacts, and one of them lists my google-scholar url.

** Summary

This looks like the foundation of a mongo/emacs-lisp interface. This interface is not that fast though, and suffers from some limitations related to the use of the shell. Depending on the actual use, it is clear you can gain performance by passing some work on the database, which requires some javascript coding. Even that revealed some subtlety, e.g. making sure the database output text that was compatible with the lisp reader. That mostly means taking care of quotes, and other special characters, which I managed with a simple escape mechanism. It is probably worth investing a few more days in building an interface that uses a process and communicates with the mongo cli directly before moving forward with any significant application that uses Mongo in emacs. There are many good ideas for that:

1. Index all your org files (e.g. http://kitchingroup.cheme.cmu.edu/blog/2017/01/03/Find-stuff-in-org-mode-anywhere/)
2. Index all your bibtex files (e.g. http://kitchingroup.cheme.cmu.edu/blog/2017/01/15/Querying-a-MongoDB-bibtex-database-with-Python-and-emacs-lisp/)
3. Download RSS feeds into a searchable database
4. Manage your contacts
5. Index your email? mu and notmuch use xapian for this, but I have found they cannot search for things like hashtags. Maybe MongoDB would be better?

The tradeoffs between this and sqlite are more clear now. With Mongo we do not have to create the normalized tables (although it is still a good idea to think about how to structure the documents, and if they should be a little normalized). It is /much/ easier to map lisp data structures to Mongo queries than it is to do that with SQL queries. On the other hand, it is necessary to do some javascript programming with Mongo to get some desired output. It still seems worth exploring further.
* DONE ob-ipython and inline figures in org-mode
  CLOSED: [2017-01-29 Sun 16:05]
  :PROPERTIES:
  :categories: python,ipython
  :date:     2017/01/29 16:05:22
  :updated:  2017/01/29 16:05:22
  :END:

[[https://github.com/gregsexton/ob-ipython][ob-ipython]] provides some nice support for inline images, but it is a little limited. You can only have one inline plot, and you cannot capture the printed output. I often want both, and use more than one figure in a code block. So, here I look at a way to get that.

When ob-ipython executes a cell, it gets two things internally: the output and a list of result elements. The output is all the stuff that is printed, and the result contains result cells. So, we just have to check these for images, and append them to the output in an appropriate way.  I will do that using file links so that org automatically renders them. We will save the images as temp files, since they are regenerated each time you run the cell.

I want output and inline figures. This ipython block should output some text and two figures. Note we do not define file names anywhere! See [[id:44FC1FFF-A6EA-466E-B61C-85B22E58781D][this section]] for details on how to get ob-ipython to do this.

#+BEGIN_SRC ipython :session :results output drawer
%matplotlib inline
import matplotlib.pyplot as plt
import numpy as np

t = np.linspace(0, 20 * np.pi, 350)
x = np.exp(-0.1 * t) * np.sin(t)
y = np.exp(-0.1 * t) * np.cos(t)

plt.plot(x, y)
plt.axis('equal')

plt.figure()
plt.plot(y, x)
plt.axis('equal')

print('Length of t = {}'.format(len(t)))
print('x .dot. y = {}'.format(x @ y))
#+END_SRC

#+RESULTS:
:RESULTS:
Length of t = 350
x .dot. y = 1.3598389888491538
[[file:/var/folders/5q/lllv2yf95hg_n6h6kjttbmdw0000gn/T/ob-ipython-86557tr2.png]]
[[file:/var/folders/5q/lllv2yf95hg_n6h6kjttbmdw0000gn/T/ob-ipython-86557f1F.png]]
:END:

Nice, success! Now my code blocks [[http://kitchingroup.cheme.cmu.edu/blog/2017/01/21/Exporting-org-mode-to-Jupyter-notebooks/][export more cleanly to jupyter notebooks]]. Speaking of which, if you liked the post on that, there is a new library for it in scimax: https://github.com/jkitchin/scimax/blob/master/ox-ipynb.el. Yes, one day I will put it in its own repo, and probably put it up on MELPA. If it turns out to be useful over the next semester.



** code for getting output and inline figures
   :PROPERTIES:
   :ID:       44FC1FFF-A6EA-466E-B61C-85B22E58781D
   :END:

I wrote one new function that writes the base64 data out to a temporary file and returns a link to it. Then, I modified the org-babel-execute:ipython function to append these links onto the output. It seems like you need to use a header like this in your ob-ipython block, notably the results need to be in a drawer like this if you want org-mode to render the images. They do not show up in the results that have colons starting them.

#+BEGIN_EXAMPLE
#+BEGIN_SRC ipython :session :results output drawer
#+END_EXAMPLE

Here is the code.

#+BEGIN_SRC emacs-lisp
(defun ob-ipython-inline-image (b64-string)
  "Write the b64-string to a temporary file.
Returns an org-link to the file."
  (let* ((tfile (make-temp-file "ob-ipython-" nil ".png"))
	 (link (format "[[file:%s]]" tfile)))
    (ob-ipython--write-base64-string tfile b64-string)
    link))


(defun org-babel-execute:ipython (body params)
  "Execute a block of IPython code with Babel.
This function is called by `org-babel-execute-src-block'."
  (let* ((file (cdr (assoc :file params)))
         (session (cdr (assoc :session params)))
         (result-type (cdr (assoc :result-type params))))
    (org-babel-ipython-initiate-session session params)
    (-when-let (ret (ob-ipython--eval
                     (ob-ipython--execute-request
                      (org-babel-expand-body:generic (encode-coding-string body 'utf-8)
                                                     params (org-babel-variable-assignments:python params))
                      (ob-ipython--normalize-session session))))
      (let ((result (cdr (assoc :result ret)))
            (output (cdr (assoc :output ret))))
        (if (eq result-type 'output)
	    (concat
	     output
	     (format "%s"
		     (mapconcat 'identity
				(loop for res in result
				      if (eq 'image/png (car res))
				      collect (ob-ipython-inline-image (cdr res)))
				"\n")))
          (ob-ipython--create-stdout-buffer output)
          (cond ((and file (string= (f-ext file) "png"))
                 (->> result (assoc 'image/png) cdr (ob-ipython--write-base64-string file)))
                ((and file (string= (f-ext file) "svg"))
                 (->> result (assoc 'image/svg+xml) cdr (ob-ipython--write-string-to-file file)))
                (file (error "%s is currently an unsupported file extension." (f-ext file)))
                (t (->> result (assoc 'text/plain) cdr))))))))
#+END_SRC

#+RESULTS:
: org-babel-execute:ipython
* Superpowered email in Emacs

Gmail does a few things right: awesome search, email completion. I am not a big fan of writing email in a browser though. You know, because I like editing text in Emacs.

I treat email primarily as an inbox of messages I need to do something with. My preference is to read an email, and either respond and archive, archive or delete it. If I can not do one of those things, the email should go on a todo list for me to handle later. If a message is in the inbox, it means it is waiting for me to do something. I try to keep under 50 emails in my inbox at any given time, and those are emails I usually plan to handle within a few days (or it goes on a todo list).

** TODO Attachment reminder
** Highlight some words from specific users

I get some automated reports from a computer cluster. These reports tell me if the RAID array is in Optimal, Degraded or Missing status. To make it easier to read these, I want those words to be highlighted in color. I especially want words like Degraded and Missing to be red so they stand out! This snippet highlights those words, but only in emails from the cluster. This is an example of conditionally changing the appearance of an email.

#+BEGIN_SRC emacs-lisp :results silent
(defun gilgamesh-fontify ()
  (loop for (name . email) in (mu4e-message-field-at-point :from)
	do
	(when (string= email "root@gilgamesh.cheme.cmu.edu")
	  (hi-lock-mode 1)
	  (highlight-regexp "Optimal" 'mu4e-modeline-face) ; a greenish color
	  (highlight-regexp "Degraded" 'mu4e-warning-face) ; a reddish color
	  (highlight-regexp "Missing" 'mu4e-warning-face))))

(add-hook 'mu4e-view-mode-hook 'gilgamesh-fontify)
#+END_SRC

** Mail merge

Many times I collect information from people by email. I like to send individual emails, rather than one email to the whole group. It makes it simpler for me to aggregate the data they send me, and I get individual email threads. If the information is sufficiently structured, it is easy to use the mail-merge feature of scimax to generate and send the emails.

Mail merge is a multi-step process

1. Create a data source (usually a table) that has all the information you need. Each row in the table will end up being one email. Give the table a name, so it can be the input for a source block later.

#+name: mail-merge-data
| email              | first name | last name | file       |
|--------------------+------------+-----------+------------|
| some@person.com    | Some       | One       | tees.org   |
| another@person.com | Another    | Person    | shorts.org |

2. Create a template using ${identifier} tags that will be replaced by things in the template by data from the data-source using s-format. I like to put these in a named example block like this so it is easy to include in a source block later. This block uses a personal name to address the person, tells them to check on a file, and attaches the file to the email. Note this also puts an id link in the message. If they reply, and that link is there, I can type C-c o on it and jump back to the heading where I sent the message from. I might copy some data from the message there.

#+name: email-template
#+BEGIN_EXAMPLE
Dear ${NAME},

Please check this file: ${FILE}. It is attached.

-----------------------
Please do not delete this.
[[id:${ID}]]

<#part type="application/octet-stream" filename="${PATH}" disposition=attachment>
<#/part>
#+END_EXAMPLE

3. Generate the messages using `mail-merge-make-headings'. You need to create a new data-source that defines the fields in the template, and the heading properties TO and SUBJECT. This will generate a subheading called Messages in the current heading. Each message will be a subsubheading, and initially tagged :unsent:.

#+BEGIN_SRC emacs-lisp :var data=mail-merge-data template=email-template
(let ((data-source (loop for (email fname lname file) in data
			 collect
			 `(("TO" . ,email)
			   ("SUBJECT" . ,(format "Meeting notes about %s" file))
			   ("HEADLINE" . ,(format "Message to %s %s" fname lname))
			   ("NAME" . ,fname)
			   ("FILE" . ,file)
			   ("PATH" . ,(expand-file-name file))))))
  (mail-merge-make-headings template data-source)))
#+END_SRC

#+RESULTS:

4. Inspect each message. You can edit these messages by hand, or modify the template/code above and re-run them. If a message is good, send it with M-x mail-merge-send-heading (which opens a message buffer and you have to C-c C-c to send it). I always do this for the first few to make sure the messages are formatted correctly. Once I am sure of that, C-u M-x mail-merge-send-heading will send the message directly. Both tag the message as sent, and add some properties about when the message was sent, stores a link to the sent message, and  move the point to the next unsent message. I actually use speed keys for this. When you are on the first star of the message headline, pressing m will open the message buffer for you to send, and pressing s will just send it. If you are super confident, you can use M-x mail-merge and it will send all headlines that are tagged unsent with a TO property with a 0.2 second delay.




*** Messages
**** DONE Message to Some One                                          :sent:
     CLOSED: [2017-01-07 Sat 15:17]
     :PROPERTIES:
     :ID: 35BD9490-4380-4062-A445-AF14718584FD
     :TO:       some@person.com
     :SUBJECT:  Meeting notes
     :SENT-ON:  Sat Jan  7 15:18:07 2017
     :Message-ID: [[mu4e:msgid:m2pojyfwua.fsf@Johns-MacBook-Air.local][Meeting notes (Sat Jan  7 15:18:07 2017)]
     :END:
Dear Some,

Please check this file: tees.org. It is attached.

-----------------------
Please do not delete this.
[[id:35BD9490-4380-4062-A445-AF14718584FD]]


**** Message to Another Person :sent:
     :PROPERTIES:
     :ID: A32AF98B-DC16-48BE-88FA-A3B7C879D931
     :TO:       another@person.com
     :SUBJECT:  Meeting notes
     :SENT-ON:  Sat Jan  7 15:17:48 2017
     :Message-ID: [[mu4e:msgid:m2shoufwut.fsf@Johns-MacBook-Air.local][Meeting notes (Sat Jan  7 15:17:48 2017)]]
     :END:
Dear Another,

Please check this file: shorts.org. It is attached.

-----------------------
Please do not delete this.
[[id:A32AF98B-DC16-48BE-88FA-A3B7C879D931]]

<#part type=\"application/octet-stream\" filename=\"/Users/jkitchin/vc/blogofile-jkitchin.github.com/_blog/shorts.org\" disposition=attachment>
<#/part>

** Triggering followup actions on replies

A sent message has a message-id and when people reply to it, that id should be in a references header field. We can set up a hook that alerts us when someone replies to a specific email. This will be triggered on every view, so you might be careful about what the action does.

#+BEGIN_SRC emacs-lisp
(setq email-notifications '(("m28tqmhobn.fsf@Johns-MacBook-Air.local" . (message-box "Followup!"))))

(defun check-for-followup ()
  (loop for (ref . action) in email-notifications
	do
	(message "%s: %S against %S"
		 (-contains? (mu4e-message-field-at-point :references) ref)
		 ref (mu4e-message-field-at-point :references))
	(when (-contains? (mu4e-message-field-at-point :references) ref)
	  (message "confirmed")
	  (eval action))))

(add-hook 'mu4e-view-mode-hook 'check-for-followup)
#+END_SRC

#+RESULTS:
| check-for-followup | gilgamesh-fontify | mu4e-auto-tag | email-fontify | #[nil \301\300!\210\302\211\207 [bookmark-make-record-function make-local-variable mu4e-view-bookmark-make-record] 2] |

** Tagging emails

** Automatic tagging

* A comint mode for mongo
Adapted from: https://www.masteringemacs.org/article/comint-writing-command-interpreter


** Testing dates

#+BEGIN_SRC emacs-lisp
(mongo-cmd "use test")
#+END_SRC

#+RESULTS:
: switched to db test


#+BEGIN_SRC emacs-lisp
(mongo--unquote-query '((date-added . "<js>new Date()</js>")))
#+END_SRC

#+RESULTS:
: {"date-added":new Date()}

#+BEGIN_SRC emacs-lisp
(mongo-insert "test" '((date-added . "<js>new Date()</js>")))
#+END_SRC

#+RESULTS:
: ((nInserted . 1))

#+BEGIN_SRC emacs-lisp
(mongo-find "test" '((_id . "<js>ObjectId('589f598c0a25be50ecd9a6d1')</js>")))
#+END_SRC

#+RESULTS:
: [((_id . "ObjectId(\"589f598c0a25be50ecd9a6d1\")") (date-added . "ISODate(\"2017-02-11T18:35:56.634Z\")"))]

#+BEGIN_SRC emacs-lisp
(json-encode '((_id . "<js>ObjectId(\"589f598c0a25be50ecd9a6d1\")</js>")))
#+END_SRC

#+RESULTS:
: {"_id":"<js>ObjectId(\"589f598c0a25be50ecd9a6d1\")</js>"}

#+BEGIN_SRC emacs-lisp
(mongo--unquote-query '((_id . "<js>ObjectId('589f598c0a25be50ecd9a6d1')</js>")))
#+END_SRC

#+RESULTS:
: {"_id":ObjectId('589f598c0a25be50ecd9a6d1')}



** using commands with comint

#+BEGIN_SRC emacs-lisp
(mongo-connect)
#+END_SRC

#+RESULTS:

#+BEGIN_SRC emacs-lisp
(mongo-cmd "use bibtex")
#+END_SRC

#+RESULTS:
: switched to db bibtex

#+BEGIN_SRC emacs-lisp
(mongo-cmd "show dbs")
#+END_SRC

#+RESULTS:
: admin     0.000GB
: ase       0.000GB
: contacts  0.000GB
: local     0.000GB
: test      0.007GB



#+BEGIN_SRC emacs-lisp
(mongo-cmd "db.contacts.count()")
#+END_SRC

#+RESULTS:
: 0

#+BEGIN_SRC emacs-lisp
(mongo-use "contacts")
(mongo-count "entries")
#+END_SRC

#+RESULTS:
: 3

#+BEGIN_SRC emacs-lisp
(mongo-insert "entries" (loop for contact in contacts
			      collect
			      (append `(,(cons 'desc (car contact))) (cdr contact))))
#+END_SRC

#+RESULTS:
: 2017

#+BEGIN_SRC emacs-lisp
(mongo-count "entries")
#+END_SRC

#+RESULTS:
: 3

#+BEGIN_SRC emacs-lisp
(mongo-count "contacts" nil '((limit . 5)))
#+END_SRC

#+RESULTS:
: 0

#+BEGIN_SRC emacs-lisp
(mongo-insert "entries" '((name . "John Kitchin")))
#+END_SRC

#+RESULTS:
: ((nInserted . 1))



#+BEGIN_SRC emacs-lisp :results code
(mongo-find "contacts" '((EMAIL . (($regex . "cmu.edu")))))
#+END_SRC

#+RESULTS:
#+BEGIN_SRC emacs-lisp
[]
#+END_SRC




#+BEGIN_SRC emacs-lisp
(mongo-update "contacts" '((name . "John Kitchin")) '((email . "test")))
#+END_SRC

#+RESULTS:
: ((nMatched . 1) (nUpserted . 0) (nModified . 1))

#+BEGIN_SRC emacs-lisp
(mongo-update "contacts" '((name . "John Kitchin")) '(($set . ((email . "test")))))
#+END_SRC

#+RESULTS:
: ((nMatched . 1) (nUpserted . 0) (nModified . 1))

#+BEGIN_SRC emacs-lisp
(mongo-deleteMany "contacts" '((name . "John Kitchin")))
#+END_SRC

#+RESULTS:
: ((acknowledged . t) (deletedCount . 0))

#+BEGIN_SRC emacs-lisp
(mongo-count "contacts")
#+END_SRC

#+RESULTS:
: 6

#+BEGIN_SRC emacs-lisp
(mongo-drop "contacts")
#+END_SRC

#+RESULTS:
: true
#+BEGIN_SRC emacs-lisp
(mongo-dropDatabase)
#+END_SRC

#+RESULTS:
: {  "dropped" : "bibtex",  "ok" : 1 }

#+BEGIN_SRC emacs-lisp
(mongo-use "contacts")
#+END_SRC

#+RESULTS:
: switched to db contacts

* ISSN database

#+BEGIN_SRC ipython :session :results output drawer
import glob

files = glob.glob('/Users/jkitchin/.scopus/issn/*')
print(len(files))
#+END_SRC

#+RESULTS:
:RESULTS:
909
:END:

Data from http://www.cas.org/content/references/corejournals

#+BEGIN_SRC ipython :session :results output drawer
from bs4 import BeautifulSoup

with open('cas.html') as f:
    html = BeautifulSoup(f.read())

cas_data = {}

rows = html.find_all('tr')

while len(rows) > 0:
    row = rows.pop().find_all('td')
    if row[0].text == '\xa0':
        if title == '': title = abbrv
        cas_data[title] = {'coden': coden,
                         'abbrev': [abbrv]}

    # full title row
    if row[1].text == ' ':
        title = row[0].text.strip()
    else:
        abbrv = row[0].text.strip()
        coden = row[1].text.strip()
#+END_SRC

#+RESULTS:
:RESULTS:
:END:


#+BEGIN_SRC ipython :session :results output drawer
import xml.etree.ElementTree as ET

ns = {'dtd': 'http://www.elsevier.com/xml/svapi/abstract/dtd',
      'ait': "http://www.elsevier.com/xml/ani/ait",
      'cto': "http://www.elsevier.com/xml/cto/dtd",
      'xocs': "http://www.elsevier.com/xml/xocs/dtd",
      'ce': 'http://www.elsevier.com/xml/ani/common',
      'prism': 'http://prismstandard.org/namespaces/basic/2.0/',
      'xsi': "http://www.w3.org/2001/XMLSchema-instance",
      'dc': 'http://purl.org/dc/elements/1.1/',
      'atom': 'http://www.w3.org/2005/Atom',
      'opensearch': 'http://a9.com/-/spec/opensearch/1.1/'}

data = {}

for xf in files:

    with open(xf) as f:
        text = f.read()
        xml = ET.fromstring(text)

        issn = xml.find('entry/prism:issn', ns)
        title = xml.find('entry/dc:title', ns)
        url = xml.find('entry/link[@ref="homepage"]')

        if issn is not None:
            tissn = issn.text.strip()
            ttitle = title.text.strip()

            if url is not None:
                turl = url.get('href').strip()
            else:
                turl = None

            if ttitle in cas_data:
                coden = cas_data[ttitle]['coden']
                abbrev = cas_data[ttitle]['abbrev']
            else:
                coden = None
                abbrev = None

            data[tissn] = {'title': ttitle, 'url': turl, 'coden': coden, 'abbrev': abbrev}



import json
with open('journal-issn.json', 'w') as f:
    f.write(json.dumps(data,
                       sort_keys=True,
                       indent=4))
#+END_SRC

#+RESULTS:
:RESULTS:
:END:

data['0000-0000-documentation'] = '''Database of journal properties.
The key of each entry is an issn number. Each entry has the following keys:
title - The name of the journal
url - The journal homepage
coden - a six character, alphanumeric bibliographic code, that provides concise, unique and unambiguous identification of the titles of periodicals and non-serial publications from all subject areas
abbrev - A list of abbreviations for the journal name.

The coden and abbrev may be null.

The data for coden and abbrev was derived from http://www.cas.org/content/references/corejournals.

The issn, title and url was derived from Scopus data previously downloaded by John Kitchin.'''
* TODO [#B] A MongoDB bibtex database                                   :tag:
#+BEGIN_SRC emacs-lisp
(mongo-connect)
#+END_SRC

#+RESULTS:

First we select a database.
#+BEGIN_SRC emacs-lisp
(mongo-use "bibtex")
#+END_SRC

#+RESULTS:
: switched to db bibtex

Now, we add each entry.

#+BEGIN_SRC emacs-lisp
(find-file "../../../Dropbox/bibliography/references.bib")

(bibtex-map-entries
 (lambda (key start end)
   (goto-char start)
   (mongo-insert "entries" (append
			    (date-added . (js "new Date()"))
			    (bibtex-parse-entry t)))))
#+END_SRC

#+RESULTS:

#+BEGIN_SRC emacs-lisp
(mongo-count "entries")
#+END_SRC

#+RESULTS:
: 1678

#+BEGIN_SRC emacs-lisp
(mongo-find "entries" '((year . "1994") (author . (($regex . "Normal")))))
#+END_SRC

#+RESULTS:
: [((_id . "ObjectId(\"589e08ef6137c9948bbc2f1c\")") (=type= . "article") (=key= . "klassen-1994-h2o2-deter") (author . "Klassen, Normal V. and Marchington, David and McGowan, Heather
:                   C.E.") (title . "\\ce{h_2o_2} Determination By the \\ce{I_3^-} Method and By
:                   \\ce{KMnO_4} Titration") (journal . "Analytical Chemistry") (volume . "66") (number . "18") (pages . "2921-2925") (year . "1994") (doi . "10.1021/ac00090a020") (url . "http://pubs.acs.org/doi/abs/10.1021/ac00090a020") (eprint . "http://pubs.acs.org/doi/pdf/10.1021/ac00090a020"))]


#+BEGIN_SRC emacs-lisp
(setq mongo-output '(""))
#+END_SRC

#+RESULTS:
|   |
* File properties in emacs-lisp
  :PROPERTIES:
  :ID:       B22C65AB-9EE6-4F79-83D3-41C177A2A1AB
  :END:

Here we get attributes of a file. there are a lot of them. The 5th one is the last modified time in tuple form.
#+BEGIN_SRC emacs-lisp
(file-attributes "blog.org")
#+END_SRC

#+RESULTS:
| nil | 1 | 501 | 20 | (22687 12765 0 0) | (22686 5427 0 0) | (22686 5427 0 0) | 73539 | -rw-r--r-- | t | 11308089 | 16777220 |

Here is a human readable last modified time.
#+BEGIN_SRC emacs-lisp
(format-time-string "%Y-%m-%dT%H:%M:%S" (nth 5 (file-attributes "blog.org")))
(format-time-string "%FT%T%z" (nth 5 (file-attributes "blog.org")))
#+END_SRC

#+RESULTS:
: 2017-02-11T13:16:27-0500

Here we can get the current time in tuple form.
#+BEGIN_SRC emacs-lisp
(current-time)
#+END_SRC

#+RESULTS:
| 22696 | 22502 | 327615 | 0 |

We can check if T1 is earlier than T2 like this.

#+BEGIN_SRC emacs-lisp
(time-less-p  (nth 5 (file-attributes "blog.org")) (current-time))
#+END_SRC

#+RESULTS:
: t

So, we should store the time updated. Then, if the time updated is earlier than the last time modified, it is time to update again.

For contacts:

We need a list of files, and the last time they were updated.

contact-hash-table:

{contact-uuid: {display: string,
                **properties}


#+BEGIN_SRC emacs-lisp
(defun contacts-generate-display-string-from-heading ()
  "Returns the display string for a contact heading."
  (substring-no-properties
   (format "|%s|%s|%s|%45s | %40s | %30s | %s"
	   (if (org-entry-get (point) "PHONE") "P" " ")
	   (if (org-entry-get (point) "URL") "W" " ")
	   (if (org-entry-get (point) "SCOPUSID") "S" " ")
	   (format "%s%s"
		   (org-get-heading t t)
		   (if (org-entry-get (point) "ALIASES")
		       (format " (%s)" (org-entry-get (point) "ALIASES"))
		     ""))
	   (org-entry-get (point) "EMAIL")
	   (let ((tags (org-get-tags-at)))
	     (if tags
		 (concat ":" (s-join ":" tags) ":")
	       ""))
	   (buffer-file-name))))
#+END_SRC

#+RESULTS:
: contacts-generate-display-string-from-heading

#+BEGIN_SRC emacs-lisp
(defun contacts-generate-data-from-heading ()
  "Generate a data structure for the contact."
  (let* ((properties (org-entry-properties))
	 (data (append properties
		       (list (cons "POSITION" (point)))
		       (list (cons "display" (contacts-generate-display-string-from-heading))))))
    (cons
     (org-id-get-create)
     (ht<-alist data))))
#+END_SRC

#+RESULTS:
: contacts-generate-data-from-heading

An initial draft
#+BEGIN_SRC emacs-lisp
(setq cdb (ht<-alist (org-map-entries #'contacts-generate-data-from-heading "EMAIL<>\"\"")))
#+END_SRC

#+RESULTS:
: #s(hash-table size 65 test equal rehash-size 1.5 rehash-threshold 0.8 data ("93B1A269-4E3B-4B90-8829-33C15A451E11" #s(hash-table size 65 test equal rehash-size 1.5 rehash-threshold 0.8 data ("display" "| | | |                                  Test Person |                       test@someplace.com |                                | /Users/jkitchin/vc/blogofile-jkitchin.github.com/_blog/blog.org" "POSITION" 81749 "ITEM" "Test Person" "PRIORITY" "B" "FILE" "/Users/jkitchin/vc/blogofile-jkitchin.github.com/_blog/blog.org" "BLOCKED" "" "EMAIL" "test@someplace.com" "ID" "93B1A269-4E3B-4B90-8829-33C15A451E11" "CATEGORY" "blog"))))


#+BEGIN_SRC emacs-lisp
(ht-get (ht-get cdb "93B1A269-4E3B-4B90-8829-33C15A451E11") "POSITION")
#+END_SRC

#+RESULTS:
: 81749

This gets all the display strings.

#+BEGIN_SRC emacs-lisp
(ht-map (lambda (key val) (ht-get val "display")) cdb)
#+END_SRC

#+RESULTS:
|   |   |   |   | Test Person | test@someplace.com |   | /Users/jkitchin/vc/blogofile-jkitchin.github.com/_blog/blog.org |


I am a little torn on the best key value. The uuid makes updates easy. I will search on the display strings though. We need an auxiliary data structure for selection. It might look like this

#+BEGIN_SRC emacs-lisp
(ht<-alist (ht-map (lambda (key val)
		     (list
		      (cons "display" (ht-get val "display"))
		      (cons "FILE" (ht-get val "FILE"))
		      (cons "POSITION" (ht-get val "POSITION")))) cdb))
#+END_SRC

#+RESULTS:
: #s(hash-table size 65 test equal rehash-size 1.5 rehash-threshold 0.8 data (("display" . "| | | |                                  Test Person |                       test@someplace.com |                                | /Users/jkitchin/vc/blogofile-jkitchin.github.com/_blog/blog.org") (("FILE" . "/Users/jkitchin/vc/blogofile-jkitchin.github.com/_blog/blog.org") ("POSITION" . 81749))))


Map over files, and collect all the entries.


** Contacts
*** Test Person
    :PROPERTIES:
    :EMAIL:    test@someplace.com
    :ID:       93B1A269-4E3B-4B90-8829-33C15A451E11
    :END:

(contacts-generate-data)
* org-db in Mongo
  :PROPERTIES:
  :ID:       EF133EB9-894D-4138-8884-B8004BD8F119
  :END:

First make sure mongod is running.

#+BEGIN_SRC sh
mongod --config /usr/local/etc/mongod.conf
#+END_SRC

#+RESULTS:


#+BEGIN_SRC emacs-lisp
(mongo-connect)
#+END_SRC

#+RESULTS:

#+BEGIN_SRC emacs-lisp
(mongo-use "org")
#+END_SRC

#+RESULTS:
: switched to db org

This function builds the document we will save for each heading.

#+BEGIN_SRC emacs-lisp
(defun mongo-db-org-heading-data ()
  "Gather the data to insert into the db."
  (let ((hl (org-element-context)))
    (list
     (cons 'title (substring-no-properties
		   (or (org-element-property :title hl) "")))
     (cons 'todo (substring-no-properties
		  (or (org-element-property :todo-keyword hl) "")))
     (cons 'properties  (org-entry-properties))
     (cons 'level (org-element-property :level hl))
     (cons 'priority (when (org-element-property :priority hl)
		       (char-to-string (org-element-property :priority hl))))
     (cons 'tags (org-get-tags))
     (cons 'position (point))
     (cons 'file (buffer-file-name))
     (cons 'content (buffer-substring-no-properties
		     (point)
		     (min (save-excursion (outline-next-heading) (point))
			  (point-max)))))))
#+END_SRC

#+RESULTS:
: mongo-db-org-heading-data

Now we add all the headings in this file, and make a note of when each file was last updated.

#+BEGIN_SRC emacs-lisp
(org-map-entries
 (lambda ()
   (mongo-insert "headings" (mongo-db-org-heading-data))))

(mongo-update "files"
	      `((file . ,(buffer-file-name)))
	      `((file . ,(buffer-file-name))
		(last-updated . ,(current-time)))
	      '((upsert . t)))
#+END_SRC

#+RESULTS:
: {  "nMatched" : 1,  "nUpserted" : 0,  "nModified" : 1 }
: true

#+BEGIN_SRC emacs-lisp
(mongo-count "headings")
#+END_SRC

#+RESULTS:
: 28439


Here we compare the time last updated to the last modified time. If this evaluates to true, it is time to update again.

#+BEGIN_SRC emacs-lisp
(time-less-p
 (append (cdr (assoc
	       'last-updated
	       (aref (mongo-find "files"
				 `((file . ,(buffer-file-name)))
				 '((last-updated . 1)))
		     0)))
	 nil)
 (nth 5 (file-attributes (buffer-file-name))))
#+END_SRC

#+RESULTS:
: t

Now let's try some queries. First, a list of headlines. This is what I would use for a selection buffer.

The repl is not acting reliably for very large number of results.

#+BEGIN_SRC emacs-lisp
(ivy-read "Headline: "
	  (cl-map 'list
		  (lambda (hl)
		    (list
		     (format "%65s | %s"
			     (s-pad-right
			      65 " "
			      (concat
			       (make-string (cdr (assoc 'level hl)) (string-to-char "*"))
			       " "
			       (cdr (assoc 'title hl))))
			     (cdr (assoc 'file hl)))
		     (assoc 'file hl)
		     (assoc 'position hl)))
		  (mongo-find "headings" '()
			      '((_id . 0)
				(level . 1)
				(title . 1)
				(file . 1)
				(position . 1))
			      50)))
#+END_SRC

#+RESULTS:
: ** Tuition and college size analysis                              | /Users/jkitchin/Dropbox/CMU/department/2015/scopus/2014-analysis.org

Here is an approach using a command line utility.

#+BEGIN_SRC emacs-lisp
(ivy-read "Headline: "
	  (cl-map 'list
		  (lambda (hl)
		    (list
		     (format "%65s | %35s | %s"
			     (s-pad-right
			      65 " "
			      (concat
			       (make-string (round (or (cdr (assoc 'level hl)) 0)) (string-to-char "*"))
			       " "
			       (cdr (assoc 'title hl))))
			     (if (cdr (assoc 'tags hl))
				 (concat " :"
					 (mapconcat 'identity (cdr (assoc 'tags hl)) ":")
					 ":")
			       "")
			     (cdr (assoc 'file hl)))
		     (assoc 'file hl)
		     (assoc 'position hl)))
		  (json-read-from-string
		   (shell-command-to-string
		    "mongoexport -d org -c headings --quiet --jsonArray -f title,level,tags,file,position -q \"{}\""))))
#+END_SRC

#+RESULTS:
: ** Nirala Singh                                                   |                                     | /Users/jkitchin/Box Sync/hiring-2016/README.org

It is pretty slow though. I have not profiled it, but I guess it is slow because we have to get the data, then map over it to create the candidates. Maybe it would be better to store the strings and just retrieve them.

As a reminder to myself, I did this for the following reasons:

1. To get full text search. It appears it was not going to be easy to achieve that with the emacsql/sqlite version I made before. But, that version is a lot faster at generating candidates so far.

2. To get a different query syntax. Mongo basically uses json to build the query. This is easier to programatically generate queries. emacsql is also not too bad, but I found some limitations on the mapping of sql to elisp.

3. To get more flexible document structure. With Mongo, it is easy to add new things, and it is not necessary to define new tables and columns.


** email query
This section is about #email.

db.headings.find({"properties.EMAIL": {$exists: true}})
#+BEGIN_SRC emacs-lisp
(mongo-find "headings" '((properties.EMAIL . (($exists . t)))) nil 3)
#+END_SRC

#+RESULTS:
: ObjectId("58a91ed4e71898546ac98aa0")

#+BEGIN_SRC emacs-lisp
(mongoexport "org" "headings" '((properties.EMAIL . (($exists . t)))) '("title" "properties.EMAIL") 3)
#+END_SRC

#+RESULTS:
: [((_id ($oid . "58a8f7dce71898546ac94658")) (title . "Jacob  Boes") (properties (CATEGORY . "roster") (ADDED . "[2014-07-07 Mon]") (EMAIL . "jboes@andrew.cmu.edu") (CUSTOM_ID . "jboes") (TIMESTAMP_IA . "[2014-07-07 Mon]") (BLOCKED . "") (FILE . "/Users/jkitchin/Dropbox/CMU/classes/org-course/gitolite-admin/roster.org") (PRIORITY . "B") (ITEM . "Jacob  Boes"))) ((_id ($oid . "58a8f7dce71898546ac94659")) (title . "Mehak Chawla") (properties (CATEGORY . "roster") (ADDED . "[2014-07-07 Mon]") (EMAIL . "mehakc@andrew.cmu.edu") (CUSTOM_ID . "mehakc") (BLOCKED . "") (FILE . "/Users/jkitchin/Dropbox/CMU/classes/org-course/gitolite-admin/roster.org") (PRIORITY . "B") (ITEM . "Mehak Chawla"))) ((_id ($oid . "58a8f7dce71898546ac9465a")) (title . "Qingqi Fan") (properties (CATEGORY . "roster") (ADDED . "[2014-07-07 Mon]") (EMAIL . "qingqif@andrew.cmu.edu") (CUSTOM_ID . "qingqif") (TIMESTAMP_IA . "[2014-07-07 Mon]") (BLOCKED . "") (FILE . "/Users/jkitchin/Dropbox/CMU/classes/org-course/gitolite-admin/roster.org") (PRIORITY . "B") (ITEM . "Qingqi Fan")))]

** Add a text index

#+BEGIN_SRC emacs-lisp
(mongo-ensureIndex "headings" '(("content" . "text")))
#+END_SRC

#+RESULTS:
: {  "createdCollectionAutomatically" : false,  "numIndexesBefore" : 3,  "numIndexesAfter" : 3,  "note" : "all indexes already exist",  "ok" : 1 }


#+BEGIN_SRC emacs-lisp
(cl-map 'list (lambda (hl) (format "[[elisp:(progn (find-file \"%s\")(goto-char %s))][%s]]" (cdr (assoc 'file hl)) (round (cdr (assoc 'position hl))) (cdr (assoc 'title hl))))
 (mongoexport "org" "headings" '(($text . (($search . "#email")))) '("title" "file" "position") 5))
#+END_SRC

#+RESULTS:
| [[elisp:(progn (find-file "/Users/jkitchin/Dropbox/CMU/manuscripts/2015/manuscript-corelevelshift/supporting-information/supporting-information.org")(goto-char 18231))][Getting the Computational Details of a Calculation from the JSON file]] | [[elisp:(progn (find-file "/Users/jkitchin/Dropbox/CMU/manuscripts/2015/polymorph+u/archive/32415/supporting-information.org")(goto-char 132306))][Application of Conclusions to Other BO2]] | [[elisp:(progn (find-file "/Users/jkitchin/Dropbox/org-mode/contacts/cheme-departments.org")(goto-char 174614))][Rice University]] | [[elisp:(progn (find-file "/Users/jkitchin/Dropbox/CMU/meetings/@planning/AICHE-CRE-planning/2015/analysis-2015.org")(goto-char 168261))][Submissions by state and country]] | [[elisp:(progn (find-file "/Users/jkitchin/Dropbox/kitchingroup/jmax/techela/README.org")(goto-char 1772))][edit gitolite/gitolite.conf]] |


#+BEGIN_SRC emacs-lisp
(mongoexport "org" "headings" '(($text . (($search . "cite:kitchin-2015-examp")))) '("title" "file" "position") 5)
#+END_SRC

#+RESULTS:
: [((_id ($oid . "58a8f837e71898546ac94852")) (title . "Author distribution of papers") (position . 836036.0) (file . "/Users/jkitchin/Dropbox/CMU/department/2015/scopus/dept-scopus-2014.org")) ((_id ($oid . "58a91401e71898546ac971dc")) (title . "WGS") (position . 261874.0) (file . "/Users/jkitchin/Dropbox/MATLAB/matlab-blog/tutorials.org")) ((_id ($oid . "58a8f8a9e71898546ac94d1d")) (title . "Introduction") (position . 1897.0) (file . "/Users/jkitchin/Dropbox/CMU/manuscripts/2015/data-ACS-Catalysis/supporting-information.org")) ((_id ($oid . "58a913fbe71898546ac9717f")) (title . "Method of continuity") (position . 56391.0) (file . "/Users/jkitchin/Dropbox/MATLAB/matlab-blog/tutorials.org")) ((_id ($oid . "58a91401e71898546ac971d7")) (title . "Gibbs minimization and NIST webbook") (position . 249697.0) (file . "/Users/jkitchin/Dropbox/MATLAB/matlab-blog/tutorials.org"))]

#+BEGIN_SRC emacs-lisp
(mongo-find "headings" '(($text . (($search . "kitchin")))) '((_id . 0)
		      (title . 1)
		      (position . 1)))
#+END_SRC

#+RESULTS:
: []

#+BEGIN_SRC emacs-lisp
(cl-map 'list
	(lambda (v) (format "[[elisp:(goto-char %s)][%s]]"
			    (cdr (assoc 'position v))
			    (cdr (assoc 'title v))))
	(mongo-find "headings" '((content . (($regex . "EF133EB9"))))
		    '((_id . 0)
		      (title . 1)
		      (position . 1))))
#+END_SRC

#+RESULTS:
| [[elisp:(goto-char 83117)][org-db in Mongo]] |

#+BEGIN_SRC emacs-lisp
(mongo-find "headings" '((todo . "TODO"))
		    '((_id . 0)
		      (title . 1)
		      (position . 1)))
#+END_SRC

#+RESULTS:
: [((title . "Attachment reminder") (position . 63315)) ((title . "A MongoDB bibtex database") (position . 76998))]




#+BEGIN_SRC emacs-lisp
(mongo-remove "headings" `())
#+END_SRC

#+RESULTS:
: ((nRemoved . 49))

#+BEGIN_SRC emacs-lisp
(let* ((files (emacsql org-db [:select [filename] :from files :order-by rowid :asc]))
       (N (length files))
       (enable-local-variables nil)
       (org-mode-hook '())
       buf already-open)
  (loop for (fname) in files for i from 0 to N
	if (and fname (file-exists-p fname))
	do
	(message "Refreshing %s of %s" i N)
	(mongo-remove "headings" `((file . ,fname)))
	(setq already-open (find-buffer-visiting fname))
	(setq buf (find-file-noselect fname))
	(with-current-buffer buf
	  (condition-case err
	      (org-map-entries
	       (lambda ()
		 (mongo-insert "headings" (mongo-db-org-heading-data)))))
	  (mongo-update "files"
			`((file . ,(buffer-file-name)))
			`((file . ,(buffer-file-name))
			  (last-updated . ,(current-time)))
			'((upsert . t))))
	(unless already-open (kill-buffer buf))))
#+END_SRC


#+BEGIN_SRC sh :results output
mongo --quiet localhost:27017/org test.js
#+END_SRC

#+RESULTS:
: "org-db in Mongo"
: "Add a text index"

* bson

#+BEGIN_SRC emacs-lisp
(require 'bson)
#+END_SRC

#+RESULTS:
: bson

#+BEGIN_SRC emacs-lisp
(bson-serialize-document-to-string '((test . 5)))
#+END_SRC

#+RESULTS:
:    test     
* ob-mongo

See https://github.com/krisajenkins/ob-mongo/blob/master/ob-mongo.el

#+BEGIN_SRC mongo :db org
db.headings.count()
#+END_SRC

#+RESULTS:
: 28439

#+BEGIN_SRC mongo :db org
db.headings.find({}).limit(1)
#+END_SRC

#+RESULTS:
: { "_id" : ObjectId("58a8f64ee71898546ac93865"), "title" : "Introduction", "todo" : "", "properties" : { "CATEGORY" : "2014-analysis", "BLOCKED" : "", "FILE" : "/Users/jkitchin/Dropbox/CMU/department/2015/scopus/2014-analysis.org", "PRIORITY" : "B", "ITEM" : "Introduction" }, "level" : 1, "priority" : null, "tags" : null, "position" : 152, "file" : "/Users/jkitchin/Dropbox/CMU/department/2015/scopus/2014-analysis.org", "content" : "* Introduction\nThe goals of this study are to assess the publication habits of the top 20 (as defined by the US News ranking) departments of Chemical Engineering. We examine historical publication counts for these departments. We also do a detailed analysis of the trends for the 2014 journal publications for each department. We consider how many articles were published, how many times they were cited, where they were published, and who published them. We examine trends in these metrics and their correlation with rankings. We construct a \"j-index\" for each department, which is analogous to an h-index, but applies only to the publications of 2014, and their citations as of approximately March of 2015. The goal of this analysis is to benchmark our metrics with those of the top 20.\n\nBefore getting into the detailed analysis, we refer to the \"Leiden manifesto for research metrics\"  SOcite:hicks-2015-bibliom. This document lays out 10 principles to guide research evaluation. We review these here.\n1. Quantitative evaluation should support qualitative, expert assessment.\n  These metrics are only numbers, but they can provide evidence to support our assessments, and evidence that any actions we decide to take are effective. We should not be seduced into chasing a single metric.\n2. Measure performance against the research missions of the institution, group or researcher.\n3. Protect excellence in locally relevant research.\n4. Keep data collection and analytical processes open, transparent and simple.\n5. Allow those evaluated to verify data and analysis.\n6. Account for variation by field in publication and citation practices.\n  This is a particularly valid point for this study. Some departments are dominated by different fields, and these fields have different top journals, different citation practices, and different amounts and types of funding available.\n7. Base assessment of individual researchers on a qualitative judgement of their portfolio\n8. Avoid misplaced concreteness and false precision\n9. Recognize the systemic effects of assessment and indicators\n10. Scrutinize indicators regularly and update them\n\n" }

* reagent lookup

#+attr_org: :type reagents
| Tween 20 | Sigma-Aldrich | batch-1 |
| acetone  | Fisher        |    3456 |


#+BEGIN_SRC emacs-lisp
(setq notebook-files '("blog.org"))

(defun insert-reagent ()
  "Insert a reagent as a table row."
  (interactive)
  (let ((candidates '()))
    (loop for nbfile in notebook-files
	  do
	  (setq candidates (append candidates (-flatten-n 1
					       (org-element-map (org-element-parse-buffer) 'table
						 (lambda (table)
						   (when (string=
							  "reagents"
							  (plist-get (org-export-read-attribute :attr_org table) :type))
						     (save-excursion
						       (goto-char (org-element-property :contents-begin table))
						       (org-babel-read-table)))))))))
    ;; get unique reagents
    (setq candidates (-uniq candidates))
    (setq candidates (mapcar (lambda (s)
			       (cons (mapconcat (lambda (e) (format "%s" e)) s " | ") s))
			     candidates))
    (helm :sources
	  (helm-build-sync-source "Reagents"
	    :candidates candidates
	    :action '(("Insert" . (lambda (_)
				    (loop for choice in (helm-marked-candidates)
					  do
					  (insert "| "
						  (mapconcat
						   (lambda (e)
						     (format "%s" e)) choice " | ")
						  " |")
					  (org-ctrl-c-ctrl-c)
					  (insert "\n")))))))))
#+END_SRC

#+RESULTS:
: insert-reagent


It seems like this is another application for an org-link to headline with properties to me. Like the way I use org-contacts.

** Tween 20
   :PROPERTIES:
   :BATCH:    234
   :SOURCE:   Sigma-Aldrich
   :END:
* TODO An update on Matlab in org-mode

this is not working unfortunately. The notebook itself works fine. Just this does not work with ob-ipython. I seem to get a timeout error.

In the past Matlab integration with org-mode has been spotty, and not useful on Windows. That may have changed recently. Starting around Matlab2014 there

Second, there is now a [[https://github.com/Calysto/matlab_kernel][Jupyter kernel for Matlab]]. When coupled with [[https://github.com/gregsexton/ob-ipython][ob-ipython]] and some "light" configuration, we can run Matlab inside org-mode, and even export a Jupyter Matlab notebook!

So first the configuration. You need a pretty recent version of Matlab, it looks like at least 2014. I am using 2016b here. You have to install the Matlab Engine API for Python (https://www.mathworks.com/help/matlab/matlab-engine-for-python.html). It is pretty easy, and involves changing to a directory in your Matlab installation and running "python install setup.py".

#+BEGIN_SRC sh
cd /Applications/MATLAB_R2016b.app/extern/engines/python
python install setup.py
#+END_SRC

Next install the Jupyter kernel. This is also pretty simple:

#+BEGIN_SRC sh
pip install matlab_kernel
python -m matlab_kernel install
#+END_SRC

On the Emacs side I use this to leverage ob-ipython with some default headers:

#+BEGIN_SRC emacs-lisp
(add-to-list 'org-src-lang-modes '("jupyter-matlab" . matlab))
(add-to-list 'org-latex-minted-langs '(jupyter-matlab  "matlab"))

;; set default headers for convenience
(setq org-babel-default-header-args:jupyter-matlab
      '((:results . "output replace")
	(:session . "matlab")
	(:kernel . "matlab")
	(:exports . "code")
	(:cache .   "no")
	(:noweb . "no")
	(:hlines . "no")
	(:tangle . "no")))

(defalias 'org-babel-execute:jupyter-matlab 'org-babel-execute:ipython)
(defalias 'org-babel-prep-session:jupyter-matlab 'org-babel-prep-session:ipython)
(defalias 'org-babel-jupyter-matlab-initiate-session 'org-babel-ipython-initiate-session)

(add-to-list 'org-structure-template-alist
	     '("jm" "#+BEGIN_SRC jupyter-matlab\n?\n#+END_SRC"
	       "<src lang=\"matlab\">\n?\n</src>"))
#+END_SRC

Finally, we have this src block:

#+BEGIN_SRC jupyter-matlab :async t
t = linspace(0, 6*pi, 100)
disp(t)
#+END_SRC

#+RESULTS:
: async-abcd-1234-output



#+BEGIN_SRC jupyter-matlab
plot(sin(t))
grid on
hold on
plot(cos(t), 'r')
#+END_SRC

#+BEGIN_SRC ipython :session :results output drawer
import matlab.engine
eng = matlab.engine.start_matlab()
#+END_SRC

#+BEGIN_SRC ipython :session :results output drawer
eng = matlab.engine.start_matlab("-desktop")
#+END_SRC

#+BEGIN_SRC ipython :session :results output drawer
import matlab.engine
future = matlab.engine.start_matlab(async=True)

eng = future.result()
#+END_SRC


#+BEGIN_SRC ipython :session :results output drawer
import matlab.engine
eng = matlab.engine.connect_matlab()
print(eng.sqrt(4.0))
#+END_SRC


#+BEGIN_SRC ipython :session :results output drawer
import matlab.engine
names = matlab.engine.find_matlab()
names
#+END_SRC

#+RESULTS:
:RESULTS:
:END:
* DONE A Hy macro for defining functions with docstrings on each argument
  CLOSED: [2017-03-19 Sun 19:47]
  :PROPERTIES:
  :categories: hylang,python
  :date:     2017/03/19 19:47:22
  :updated:  2017/03/19 19:53:05
  :END:

For functions with a lot of arguments, python style docstrings leave something to be desired. For one, they are not that close to the arguments, so if you have a function with say 20 arguments, the docstring might take up a whole page! That means they are hard to keep synchronized too. Let's not argue now over the merits of a function with 20+ arguments, it is enough that they exist, and are a problem.

So what are typical documentation standards? Here is a Numpy style doc string:

#+BEGIN_SRC python :results output org drawer
def func(arg1, arg2):
    """multiply arg1 and arg2

    Parameters
    ----------
    arg1 : a number
    arg2 : a number

    """
    return arg1 * arg2
#+END_SRC

It works well for a small number of arguments with limited descriptions. This is a proper docstring that is accessible by introspection and pydoc. With much longer argument lists, this falls apart. I will not pick on any code in particular here, but suffice it to say I was inspired today to think of a better way. There are some other documentation solutions at http://stackoverflow.com/questions/9195455/how-to-document-a-method-with-parameters, but None of them are better in my opinion. I want accessible docstrings by instrospection, and only if that is unavailable do I want to read the code! Finally, if I have to read the code, I want it to be easy to figure out, which means the documentation is close to the arguments.

There is bad news, I do not have one for vanilla python. Python does not even give you a way to deal with this. But, if we had a lisp, we could make a macro to help us out. In fact, we /have/ a lisp with [[http://docs.hylang.org/en/latest/][hy]]! And we can use a macro to make a  syntax that lets us keep the docstring close to the argument, /and/ that constructs a real docstring so we get help later!

Here it is:

#+BEGIN_SRC jupyter-hy
(defmacro mydef [func args &optional docstring &rest body]
  `(defn ~func [~@(map (lambda [x] (nth x 0)) args)]
     ~(+ (if docstring (+ docstring "\n\n") "")
         "Parameters\n----------\n"
         (.join "\n" (map (lambda [x]
                            (.format "{} : {}"
                                     (nth x 0)
                                     (nth x 1))) args)))
     ~@body))
#+END_SRC

#+RESULTS:

We can checkout how it expands like this:

#+BEGIN_SRC jupyter-hy
(print (macroexpand '(mydef f [(a "an int")
                               (b "an int")]
                            "some doc"
                            (* a b))))
#+END_SRC
#+RESULTS:
: ('setv' 'f' ('fn' ['a' 'b'] 'some d oc\n\nParameters\n----------\na : an int\nb : an int' ('*' 'a' 'b')))

That looks ok. Now, for an example of using that. Here is the same function we defined before, but I put the documentation for each argument with the argument.

#+BEGIN_SRC jupyter-hy
(mydef func ((arg1 "a number")
             (arg2 "a number"))
  "Multiply arg1 by arg2"
  (* arg1 arg2))
#+END_SRC

#+RESULTS:

We can use the function now like a regular function.

#+BEGIN_SRC jupyter-hy
(print (func 24 3))
#+END_SRC

#+RESULTS:
: 72

And now for the help.

#+BEGIN_SRC jupyter-hy
(help func)
#+END_SRC

#+RESULTS:
#+begin_example
Help on function func in module __main__:

func(arg1, arg2)
    Multiply arg1 by arg2

    Parameters
    ----------
    arg1 : a number
    arg2 : a number

#+end_example

Now, that should amaze and astonish you if you are a vanilla Pythonista! We have our cake, and we eat it too. You just can not make up your own syntax that way in Python. Imagine, we could add type information, validation code, etc... into that macro. Maybe it could even be possible to store argument dependent documentation on the function, say in the function dictionary. That would require some conventions I guess,  but they could become introspectable then. For example, in this vanilla Python:

#+BEGIN_SRC python :results output org drawer
def f(x): return x*x
f.__dict__['args'] = {'x': 'A number'}
print(f.__dict__)
#+END_SRC

#+RESULTS:
:RESULTS:
{'args': {'x': 'A number'}}
:END:

In the end, this does not really solve all the problems I have with current docstrings in Python. It does solve a problem with writing and reading the code by keeping documentation close to the arguments, but ultimately the docstring from Python's point of view will basically look the same. It is pretty awesome that it is even possible. Hy lisp for the win here (again!).

* DONE A better defun for emacs-lisp
  CLOSED: [2017-03-22 Wed 16:30]
  :PROPERTIES:
  :categories: emacs,macro,elisp
  :date:     2017/03/22 16:30:33
  :updated:  2017/03/22 16:30:33
  :END:

I have been thinking of better ways to write code that is more likely to have decent docstrings that are up to date, and maybe that enable automatic validation. One strategy is to keep documentation and code together, and by together I mean /close together/. The closer the better.  I made some interesting progress in the [[http://kitchingroup.cheme.cmu.edu/blog/2017/03/19/A-Hy-macro-for-defining-functions-with-docstrings-on-each-argument/][last post]], where I used a macro to let me put argument specific documentation in the same place that the argument is defined. Here I expand the idea to also provide argument default values, and validation code where the argument is defined inside the function, in addition to generating docstrings. This post is written in Emacs-lisp, mostly because I am more familiar with the macro language. The idea should apply to other lisps too.

Let's consider this prototypical, vanilla function definition, usage, and docstring.

#+BEGIN_SRC emacs-lisp
(defun f1 (arg1 arg2)
  "Add two numbers."
  (+ arg1 arg2))

;; usage
(f1 3 4)
#+END_SRC

#+RESULTS:
: 7

Here is what the help looks like from emacs.

#+BEGIN_SRC emacs-lisp
(describe-function 'f1)
#+END_SRC

#+RESULTS:
: f1 is a Lisp function.
:
: (f1 ARG1 ARG2)
:
: For more information check the manuals.
:
: Add two numbers.

It is clear I was lazy in writing the docstring; it does not even mention the arguments. There is also no validation of the arguments so if you pass a string and a number, you will get an error. There are no defaults either, so you have to provide both arguments. It seems like there could be significant room for improvement. Of course, I could bite the bullet and write a better function like this one:

#+BEGIN_SRC emacs-lisp
(defun f1a (arg1 &optional arg2)
  "Add ARG1 and ARG2 together.
ARG1 and  ARG2 should both be numbers."
  (when (null arg2) (setq arg2 2))
  (unless (and (numberp arg1) (numberp arg2)) (error "arg1 and arg2 should both be numbers"))
  (+ arg1 arg2))

(list (f1a 3 4) (f1a 3))
#+END_SRC

#+RESULTS:
| 7 | 5 |

Yes, I could do that, but it is tedious to do it all the time. And it still leaves something to be desired for me. The docstring does not say what the default value is for example, and that is hard-coded in the code, i.e. not introspectible until you look at the code.  Next we consider an alternative way to write the function. Compare that to this function definition, usage and documentation. The function definition is a little more verbose. Providing documentation, defaults and validation code in any form would make it that way no matter what.

#+BEGIN_SRC emacs-lisp
(defn f2 ((arg1 "A number" :validate numberp)
	  (arg2 "A number" :validate numberp :default 2))
  "Add the arguments."
  (+ arg1 arg2))

;; usage
(list (f2 3 4) (f2 3))
#+END_SRC

#+RESULTS:
| 7 | 5 |

#+BEGIN_SRC emacs-lisp
(describe-function 'f2)
#+END_SRC

#+RESULTS:
: f2 is a Lisp function.
:
: (f2 ARG1 &optional ARG2)
:
: For more information check the manuals.
:
: Add the arguments.
: ARG1 : A number (valid = numberp)
: ARG2 : A number (default = 2) (valid = numberp)

The documentation is built up from the information in the function definition, in a form that is mostly consistent with emacs-lisp documentation standards. =defn= is not a regular emacs-lisp function; it is a macro I developed to generate the function code. It turned out to be long, but the gist of it is that before defining the function I loop through the arguments and collect the docstrings, along with any information about default values and/or validation functions. Then I build up the list of arguments to put in the function. Then if any default values are set, I generate some code to set those values if they are not set in the function call, and finally a similar block of validation code. At the end, I construct the defun and return it. You can check out the code if you want here: https://github.com/jkitchin/scimax/blob/master/scimax-macros.el.

Let's take a look at what this code expands to.

#+BEGIN_SRC emacs-lisp :results code
(macroexpand-1
 '(defn f2 ((arg1 "A number" :validate numberp)
	    (arg2 "A number" :validate numberp :default 2))
    "Add the arguments."
    (+ arg1 arg2)))
#+END_SRC

#+RESULTS:
#+BEGIN_SRC emacs-lisp
(defun f2
    (arg1 &optional arg2)
  "Add the arguments.\nARG1 : A number (valid = numberp)\nARG2 : A number (default = 2) (valid = numberp)\n"
  (progn
    (when
	(null arg2)
      (setq arg2 2)))
  (progn
    (unless
	(funcall 'numberp arg1)
      (error "In (%s %s) Expected %s to pass %S. Got %S" "f2" "(arg1 &optional arg2)" "arg1" 'numberp arg1))
    (unless
	(funcall 'numberp arg2)
      (error "In (%s %s) Expected %s to pass %S. Got %S" "f2" "(arg1 &optional arg2)" "arg2" 'numberp arg2)))
  (+ arg1 arg2))
#+END_SRC

You can see it expands to a regular defun, with a generated docstring, generated default settings code block, and generated validation code. Pretty nice.

Let's see what happens with a function that fails the validation. We should get an error. Here we capture the error so we can see it in the post.

#+BEGIN_SRC emacs-lisp
(condition-case err
    (f2 "oak")
  (error
   (error-message-string err)))
#+END_SRC

#+RESULTS:
: In (f2 (arg1 &optional arg2)) Expected arg1 to pass numberp. Got "oak"

So we even get a useful error message when the wrong type of argument is provided. Compare that to the error message from the original version of this function. It tells us we got the wrong type, but not which argument.

#+BEGIN_SRC emacs-lisp
(condition-case err
    (f1 "oak" 4)
  (error
   (error-message-string err)))
#+END_SRC

#+RESULTS:
: Wrong type argument: number-or-marker-p, "oak"

One last example to check out the &rest argument, with validation that every arg is a number.

#+BEGIN_SRC emacs-lisp
(defn f4 ((rarg :rest
		:validate (lambda (x)
			    (-all-p 'identity (mapcar 'numberp x)))))
  "multiply all the arguments."
  (apply '* rarg))

(f4 1 2 3)
#+END_SRC

#+RESULTS:
: 6

#+BEGIN_SRC emacs-lisp
(condition-case err
    (f4 "oak" 4)
  (error
   (error-message-string err)))
#+END_SRC

#+RESULTS:
: In (f4 (&rest rarg)) Expected rarg to pass (lambda (x) (-all-p (quote identity) (mapcar (quote numberp) x))). Got ("oak" 4)

#+BEGIN_SRC emacs-lisp
(describe-function 'f4)
#+END_SRC

#+RESULTS:
: f4 is a Lisp function.
:
: (f4 &rest RARG)
:
: For more information check the manuals.
:
: multiply all the arguments.
: RARG : No documentation

That looks ok too.

** Summary

The motivation for this was to help me write better code with better documentation. Better code in the sense that it can provide run-time validation, with better feedback, and automatic documentation, including that there is none if that is the case. It is basically compatible with the regular defun, but enhances what kind of documentation is possible with less work on my part. I think it will make it easier to keep documentation in sync, since the argument documentation would be kept near the argument, and you can build in validation if you want to.

It is no news to lispers that macros are good for this kind of application.
* ZODB as a backend for ase

#+BEGIN_SRC ipython :session :results output drawer
import ZODB, ZODB.FileStorage

storage = ZODB.FileStorage.FileStorage('mydata.fs')
db = ZODB.DB(storage)
#+END_SRC

#+RESULTS:
:RESULTS:
:END:

#+BEGIN_SRC ipython :session :results output drawer
connection = db.open()
root = connection.root()
print(dir(root))
#+END_SRC

#+RESULTS:
:RESULTS:
['_MutableMapping__marker', '_PersistentMapping__super_clear', '_PersistentMapping__super_delitem', '_PersistentMapping__super_pop', '_PersistentMapping__super_popitem', '_PersistentMapping__super_setdefault', '_PersistentMapping__super_setitem', '_PersistentMapping__super_update', '__abstractmethods__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setitem__', '__setstate__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abc_cache', '_abc_negative_cache', '_abc_negative_cache_version', '_abc_registry', '_p_activate', '_p_changed', '_p_deactivate', '_p_delattr', '_p_estimated_size', '_p_getattr', '_p_invalidate', '_p_jar', '_p_mtime', '_p_oid', '_p_serial', '_p_setattr', '_p_state', '_p_status', '_p_sticky', 'clear', 'copy', 'data', 'fromkeys', 'get', 'items', 'keys', 'pop', 'popitem', 'setdefault', 'update', 'values']
:END:

#+BEGIN_SRC ipython :session :results output drawer
from ZODB import DB
from ZODB.FileStorage import FileStorage

from persistent import Persistent
from persistent.mapping import PersistentMapping
import transaction

class EMTCalculation(Persistent):
    """An EMT calculation"""

    def __init__(self, atoms):
        self.atoms = atoms
        self.results = {}

    def run(self):
        self.results = {'energy': self.atoms.get_potential_energy(),
                        'forces': self.atoms.get_forces()}
        return self.results

# get the mapping, creating an empty mapping if
# necessary
if not root.get("ase"):
    root["ase"] = {}

ase = root["ase"]
#+END_SRC

#+RESULTS:
:RESULTS:
:END:


#+BEGIN_SRC ipython :session :results output drawer
def list_ase():
    if len(ase.values()) == 0:
        print('No calculations yet')
        return

    for calc in ase.values():
        print(calc.atoms, calc.results)

def add_calc(atoms):
    # get a hash
    hsh = hashlib.sha1(pickle.dumps(atoms)).hexdigest()
    if ase.get(hsh):
        print('Already in the database')
        return
    calc = EMTCalculation(atoms)
    calc.run()
    ase[hsh] = calc
    print(hsh)
#+END_SRC

#+RESULTS:
:RESULTS:
:END:


#+BEGIN_SRC ipython :session :results output drawer
from ase.calculators.emt import EMT
from ase import Atoms

atoms = Atoms('Cu2',[[0, 0, 0], [1, 0, 0]], pbc=[False, False, False])
atoms.set_calculator(EMT())

add_calc(atoms)
#+END_SRC

#+RESULTS:
:RESULTS:
d0f382c7e41c4b6b77248f3da8c108381979ceb5
:END:

#+BEGIN_SRC ipython :session :results output drawer
print(root)
#+END_SRC

#+RESULTS:
:RESULTS:
{'ase': {'99c73d24a8119457d0e8d836e28b1b3931379cb0': <__main__.EMTCalculation object at 0x10a0e0f28>, 'd0f382c7e41c4b6b77248f3da8c108381979ceb5': <__main__.EMTCalculation object at 0x10a0e05f8>, '5aefcdaab0eb24d28062e238cbfec40944441690': <__main__.EMTCalculation object at 0x10a0e0d68>, '28cc822bfc8e6ef8817e433b23f128a3a905ce1d': <__main__.EMTCalculation object at 0x10a0e0eb8>, '532f63584fb19cac5415356eb0a152d307f111ac': <__main__.EMTCalculation object at 0x10a0e0a58>, 'bfb6be6212359bf2ffcb148d16cdcc093cc1fee0': <__main__.EMTCalculation object at 0x10a0e0c18>, '9f80d849fb0e533bd2d21e985a3aa6f6bafbfab2': <__main__.EMTCalculation object at 0x10a0e0e48>, '52cd6466bbd04f095d63d9d44afc6d6fec4fe31b': <__main__.EMTCalculation object at 0x10a0e0cf8>, '469f5dc165baecc49bdafec4a812a9d772e55834': <__main__.EMTCalculation object at 0x10a0e0c88>}}
:END:

#+BEGIN_SRC ipython :session :results output drawer
list_ase()
#+END_SRC

#+RESULTS:
:RESULTS:
Atoms(symbols='Cu2', pbc=False, calculator=EMT(...)) {'energy': 3.4801651516252186, 'forces': array([[-3.98082236,  0.        ,  0.        ],
       [ 3.98082236,  0.        ,  0.        ]])}
Atoms(symbols='Cu2', pbc=False, calculator=EMT(...)) {'energy': 72.73118658363785, 'forces': array([[-236.97475083,    0.        ,    0.        ],
       [ 236.97475083,    0.        ,    0.        ]])}
Atoms(symbols='Cu2', pbc=False, calculator=EMT(...)) {'energy': 7.02, 'forces': array([[ 0.,  0.,  0.],
       [ 0.,  0.,  0.]])}
Atoms(symbols='Cu2', pbc=False, calculator=EMT(...)) {'energy': 6.5916577155106575, 'forces': array([[ 0.68555172,  0.        ,  0.        ],
       [-0.68555172,  0.        ,  0.        ]])}
Atoms(symbols='Cu2', pbc=False, calculator=EMT(...)) {'energy': 7.02, 'forces': array([[ 0.,  0.,  0.],
       [ 0.,  0.,  0.]])}
Atoms(symbols='Cu2', pbc=False, calculator=EMT(...)) {'energy': 6.939039181478011, 'forces': array([[ 0.13913329,  0.        ,  0.        ],
       [-0.13913329,  0.        ,  0.        ]])}
Atoms(symbols='Cu2', pbc=False, calculator=EMT(...)) {'energy': 7.02, 'forces': array([[ 0.,  0.,  0.],
       [ 0.,  0.,  0.]])}
Atoms(symbols='Cu2', pbc=False, calculator=EMT(...)) {'energy': 7.02, 'forces': array([[ 0.,  0.,  0.],
       [ 0.,  0.,  0.]])}
Atoms(symbols='Cu2', pbc=False, calculator=EMT(...)) {'energy': 7.02, 'forces': array([[ 0.,  0.,  0.],
       [ 0.,  0.,  0.]])}
:END:

#+BEGIN_SRC ipython :session :results output drawer
# close database
connection.close()
#+END_SRC


The hash key I use may change for different pickle algorithms. On one hand, it is brief code.

I do not see a great search tool here that does not involve linear search. One solution seems to be coupled to postgresql http://www.newtdb.org/en/latest/how-it-works.html.
* COMMENT SQLAlchemy as an ASE database

http://docs.sqlalchemy.org/en/latest/orm/tutorial.html

#+BEGIN_SRC ipython :session :results output drawer
import sqlalchemy
from sqlalchemy import create_engine
engine = create_engine('sqlite:///:memory:', echo=True)
#+END_SRC



#+BEGIN_SRC ipython :session :results output drawer
from sqlalchemy.ext.declarative import declarative_base
Base = declarative_base()
from sqlalchemy import Column, Integer, String, PickleType
#+END_SRC

#+RESULTS:
:RESULTS:
:END:

#+BEGIN_SRC ipython :session :results output drawer
class EMTCalculation(Base):
    __tablename__ = 'EMT'

    id = Column(Integer, primary_key=True)
    hash = Column(String)
    atoms = Column(PickleType)

    def __repr__(self):
        return '{}'.format(self.atoms)

Base.metadata.create_all(engine)
#+END_SRC

#+RESULTS:
:RESULTS:
2017-03-30 08:50:47,273 INFO sqlalchemy.engine.base.Engine PRAGMA table_info("EMT")
2017-03-30 08:50:47,274 INFO sqlalchemy.engine.base.Engine ()
2017-03-30 08:50:47,276 INFO sqlalchemy.engine.base.Engine
CREATE TABLE "EMT" (
	id INTEGER NOT NULL,
	hash VARCHAR,
	atoms BLOB,
	PRIMARY KEY (id)
)


2017-03-30 08:50:47,277 INFO sqlalchemy.engine.base.Engine ()
2017-03-30 08:50:47,279 INFO sqlalchemy.engine.base.Engine COMMIT
:END:


#+BEGIN_SRC ipython :session :results output drawer
print(EMTCalculation.__table__)
#+END_SRC

#+RESULTS:
:RESULTS:
EMT
:END:

#+BEGIN_SRC ipython :session :results output drawer
from ase.calculators.emt import EMT
from ase import Atoms

atoms = Atoms('Cu2',[[0, 0, 0], [10, 0, 0]], pbc=[False, False, False])
atoms.set_calculator(EMT())
#+END_SRC

#+RESULTS:
:RESULTS:
:END:


#+BEGIN_SRC ipython :session :results output drawer
import pickle, hashlib

def get_hash(atoms):
    return hashlib.sha1(pickle.dumps(atoms)).hexdigest()

print(get_hash(atoms))
#+END_SRC

#+RESULTS:
:RESULTS:
5aefcdaab0eb24d28062e238cbfec40944441690
:END:

Get a session

#+BEGIN_SRC ipython :session :results output drawer
from sqlalchemy.orm import sessionmaker
Session = sessionmaker(bind=engine)
session = Session()
#+END_SRC

#+RESULTS:
:RESULTS:
:END:


Make an object

#+BEGIN_SRC ipython :session :results output drawer
atoms.get_potential_energy()
e = EMTCalculation(hash=get_hash(atoms), atoms=atoms)
print(e.hash)
session.add(e)
session.commit()
#session.flush()
#+END_SRC

#+RESULTS:
:RESULTS:
07dbab28176b6e2d7e3882fa65e9612a4e3c1aef
2017-03-30 08:51:06,382 INFO sqlalchemy.engine.base.Engine BEGIN (implicit)
2017-03-30 08:51:06,384 INFO sqlalchemy.engine.base.Engine INSERT INTO "EMT" (hash, atoms) VALUES (?, ?)
2017-03-30 08:51:06,385 INFO sqlalchemy.engine.base.Engine ('07dbab28176b6e2d7e3882fa65e9612a4e3c1aef', <memory at 0x10d9daf48>)
2017-03-30 08:51:06,388 INFO sqlalchemy.engine.base.Engine COMMIT
:END:



#+BEGIN_SRC ipython :session :results output drawer
for inst in session.query(EMTCalculation):
    print(inst.atoms.get_potential_energy())
#+END_SRC

#+RESULTS:
:RESULTS:
2017-03-30 08:52:07,563 INFO sqlalchemy.engine.base.Engine SELECT "EMT".id AS "EMT_id", "EMT".hash AS "EMT_hash", "EMT".atoms AS "EMT_atoms"
FROM "EMT"
2017-03-30 08:52:07,565 INFO sqlalchemy.engine.base.Engine ()
7.02
:END:

* A spell-check buffer buffer

Spell-checking in Emacs is a one place that could use some UI work. I use flyspell which alerts me to misspellings as I type, and I have C-; bound to flyspell-correct-previous-word-generic which makes it easy to correct the last word, and I use flyspell-ivy-correct to do that. This works OK for me while writing, but it fails pretty miserably in the following scenario:

I have a long document, e.g. a proposal, or a manuscript someone has sent me and I want to spell-check it. Sure, I can run flyspell-buffer, got back to the beginning, and navigate through it with C-, (flyspell-goto-next-error), but then I still have to go through the document to check the errors, and every time I fix an error, it seems like the rest of them disappear. I consider that a bug.

What I want instead is a new buffer listing all the things tagged by flyspell as clickable links I could review and correct.

#+BEGIN_SRC emacs-lisp :lexical t
(defun flyspell-buffer-buffer ()
  "Return list of word, point line"
  (interactive)
  (save-excursion
    (goto-char (point-min))
    (flyspell-buffer)
    (let ((cb (current-buffer))
	  (ov (ov-next 'face 'flyspell-incorrect))
	  (sp '()))
      (while ov
	(goto-char (ov-beg ov))
	(push (list (buffer-substring (ov-beg ov) (ov-end ov))
		    (point)
		    (line-number-at-pos))
	      sp)
        (goto-char (ov-end ov))
	(setq ov (ov-next 'face 'flyspell-incorrect)))
      (reverse sp))))


(defun fbb-jump ()
  "Jump to position of typo."
  (interactive)
  (let ((buf (get-text-property (line-beginning-position) 'ov-buffer))
	(pos (get-text-property (line-beginning-position) 'ov-position)))
    (switch-to-buffer-other-window buf)
    (goto-char pos)))

(defvar fbb-mode-map
  (let ((map (make-sparse-keymap)))
    (define-key map (kbd "o") 'fbb-jump)
    map))


(defun fbb-refresh-list ()
  (with-current-buffer fbb-source-buffer
    (let ((entries (flyspell-buffer-buffer)))
      (setq tabulated-list-entries (loop for (word pos ln) in entries
					 collect
					 (list
					  nil
					  (vector
					   (cons word (list 'ov-buffer (current-buffer)
							    'ov-position pos))
					   "help!")))
	    tabulated-list-format (vector '("Word" 40 t)))
    (message-box "%s" entries)))
  (tabulated-list-init-header)
  (tabulated-list-print))


(define-derived-mode fbb-mode
  tabulated-list-mode "fbb"
  "Mode for viewing flyspell-buffer-buffer candidates as a tabular list.
\\{fbb-mode-map}"
  (setq tabulated-list-sort-key nil)
  (add-hook 'tabulated-list-revert-hook
	    #'fbb-refresh-list))



(defvar fbb-source-buffer nil
  "Buffer to list typos in.")

(defun fbb ()
  (interactive)
  (setq fbb-source-buffer (current-buffer))
  (switch-to-buffer-other-window (get-buffer-create "*fbb*"))
  (fbb-mode)
  (fbb-refresh-list))
#+END_SRC

#+RESULTS:
: fbb

C-, flyspell-got-next-error
C-. flyspell-auto-correct-word


bad

(load-file "fbb.el")
